{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # Importing pandas package\n",
    "\n",
    "# Set the maximum number of columns to display to None\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import numpy as np # Importing numpy package\n",
    "\n",
    "from typing import Dict, Tuple, List, Union, Optional # Importing specific types from typing module\n",
    "\n",
    "import re # Importing regular expression package\n",
    "\n",
    "from src.database_manager import DatabricksOdbcConnector # Importing DatabricksOdbcConnector class from database_manager module\n",
    "from src.utils import reorder_columns # Importing reorder_columns function from utils module\n",
    "\n",
    "from scipy.spatial.distance import cdist # Importing cdist function from scipy package\n",
    "\n",
    "import time # Importing Time Module\n",
    "\n",
    "import pyproj # Importing pyproj package\n",
    "\n",
    "from src.custom_logger import CustomLogger # Importing CustomLogger class from custom\n",
    "\n",
    "import os #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeoSurveyProcessor:\n",
    "    \"\"\"\n",
    "    A class for processing directional survey data and performing geospatial transformations\n",
    "    such as converting lat/lon to UTM, filtering heel points, and extracting key well locations.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            directional_df: pd.DataFrame = None,\n",
    "            log_dir: str = \"./logs\",\n",
    "            ):\n",
    "        \"\"\"\n",
    "        Initializes the GeoSurveyProcessor with optional header data and log directory.\n",
    "        :param header: Optional DataFrame containing header information.\n",
    "        :param log_dir: Directory for logging.\n",
    "        \"\"\"\n",
    "        self.logger = CustomLogger(\"geo_logger\", \"GeoLogger\", log_dir).get_logger()  # Custom logger\n",
    "\n",
    "        if isinstance(directional_df, pd.DataFrame):\n",
    "            self.logger.info(\"Initialized with provided DataFrame.\")\n",
    "        else:\n",
    "            self.directional_df = pd.DataFrame()\n",
    "            self.logger.warning(\"Directional Survey DataFrame is empty or not provided.\")\n",
    "        self.logger.info(\"GeoSurveyProcessor initialized.\")\n",
    "\n",
    "    def determine_utm_zone(self, longitude: float) -> int:\n",
    "        \"\"\"\n",
    "        Determines the UTM zone based on a given longitude.\n",
    "        \"\"\"\n",
    "        return int((longitude + 180) / 6) + 1\n",
    "        \n",
    "    def batch_latlon_to_utm(self, lat: np.ndarray, lon: np.ndarray, utm_zone: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Converts arrays of latitudes and longitudes to UTM coordinates in meters for a given UTM zone.\n",
    "        \"\"\"\n",
    "        proj_utm = pyproj.Transformer.from_crs(\n",
    "            \"EPSG:4326\", f\"EPSG:326{utm_zone}\", always_xy=True\n",
    "        )\n",
    "        \n",
    "        return proj_utm.transform(lon, lat)\n",
    "    \n",
    "    def compute_utm_coordinates(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Computes UTM (x, y, z) coordinates for multiple wells, using surface location to determine UTM zones.\n",
    "        Converts UTM coordinates from meters to feet. Uses vectorized batch processing for performance.\n",
    "\n",
    "        Parameters:\n",
    "        - df (pd.DataFrame): Original directional survey DataFrame.\n",
    "\n",
    "        Returns:\n",
    "        - pd.DataFrame: DataFrame with all original columns + x, y, z (in feet), and utm_zone.\n",
    "        \"\"\"\n",
    "        start_time = time.time()  # Start timing\n",
    "\n",
    "        # Step 1: Sort dataframe by md to identify surface location\n",
    "        df = df.sort_values(by=[\"chosen_id\", \"md\"], ascending=[True, True])\n",
    "        \n",
    "        # Step 2: Determine UTM zones using the surface location (first row per well)\n",
    "        surface_locs = df.groupby(\"chosen_id\").first()[[\"latitude\", \"longitude\"]]\n",
    "        surface_locs[\"utm_zone\"] = surface_locs[\"longitude\"].apply(self.determine_utm_zone)\n",
    "\n",
    "        # Merge UTM zones back into the original dataframe\n",
    "        df = df.merge(surface_locs[[\"utm_zone\"]], on=\"chosen_id\", how=\"left\")\n",
    "\n",
    "        self.logger.info(f\"✅ Determined UTM zones in {time.time() - start_time:.4f} seconds.\")\n",
    "\n",
    "        # Step 3: Batch transformation for each unique UTM zone\n",
    "        start_transform_time = time.time()\n",
    "        unique_zones = df[\"utm_zone\"].unique()\n",
    "        utm_converters: Dict[int, Tuple[np.ndarray, np.ndarray]] = {}\n",
    "\n",
    "        for zone in unique_zones:\n",
    "            subset = df[df[\"utm_zone\"] == zone]\n",
    "            easting, northing = self.batch_latlon_to_utm(subset[\"latitude\"].values, subset[\"longitude\"].values, zone)\n",
    "            utm_converters[zone] = (easting, northing)\n",
    "\n",
    "        self.logger.info(f\"✅ Performed batch EPSG transformations in {time.time() - start_transform_time:.4f} seconds.\")\n",
    "\n",
    "        # Step 4: Assign the converted coordinates back to the DataFrame\n",
    "        start_assign_time = time.time()\n",
    "        df[\"x\"], df[\"y\"] = np.zeros(len(df)), np.zeros(len(df))\n",
    "\n",
    "        for zone in unique_zones:\n",
    "            mask = df[\"utm_zone\"] == zone\n",
    "            df.loc[mask, \"x\"], df.loc[mask, \"y\"] = utm_converters[zone]\n",
    "\n",
    "        self.logger.info(f\"✅ Assigned transformed coordinates in {time.time() - start_assign_time:.4f} seconds.\")\n",
    "\n",
    "        # Step 5: Convert UTM coordinates from meters to feet (Conversion factor: 1 meter = 3.28084 feet)\n",
    "        df[\"x\"] *= 3.28084\n",
    "        df[\"y\"] *= 3.28084\n",
    "        \n",
    "        df[\"z\"] = -df[\"tvd\"] # Elevation is negative TVD\n",
    "\n",
    "        self.logger.info(f\"✅ Total execution time: {time.time() - start_time:.4f} seconds.\")\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def filter_after_heel_point(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Filters the dataframe to include all rows for each chosen_id where the first occurrence \n",
    "        of either '80' or 'heel' appears in the point_type column and all subsequent rows.\n",
    "\n",
    "        Parameters:\n",
    "        df (pd.DataFrame): A dataframe containing directional survey data with a 'chosen_id' column and 'point_type' column.\n",
    "\n",
    "        Returns:\n",
    "        pd.DataFrame: Filtered dataframe containing rows from the first occurrence of '80' or 'heel' onward.\n",
    "        \"\"\"\n",
    "\n",
    "        # Convert 'point_type' to lowercase and check for '80' or 'heel'\n",
    "        mask = df['point_type'].str.lower().str.contains(r'80|heel', regex=True, na=False)\n",
    "\n",
    "        # Identify the first occurrence for each chosen_id\n",
    "        idx_start = df[mask].groupby('chosen_id', sort=False).head(1).index\n",
    "\n",
    "        # Create a mapping of chosen_id to the starting index\n",
    "        start_idx_map = dict(zip(df.loc[idx_start, 'chosen_id'], idx_start))\n",
    "\n",
    "        # Create a boolean mask using NumPy to filter rows\n",
    "        chosen_ids = df['chosen_id'].values\n",
    "        indices = np.arange(len(df))\n",
    "\n",
    "        # Get the minimum start index for each row's chosen_id\n",
    "        start_indices = np.vectorize(start_idx_map.get, otypes=[float])(chosen_ids)\n",
    "\n",
    "        # Mask rows where index is greater than or equal to the start index\n",
    "        valid_rows = indices >= start_indices\n",
    "\n",
    "        return df[valid_rows].reset_index(drop=True)\n",
    "    \n",
    "    def get_heel_toe_midpoints_latlon(self, well_trajectory: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Extract the heel, toe, and mid-point latitude/longitude for each chosen_id in the well trajectory DataFrame\n",
    "        that has been filtered to have lateral section of the well.\n",
    "\n",
    "        Parameters:\n",
    "        well_trajectory: pd.DataFrame\n",
    "            DataFrame containing well trajectory data, including 'chosen_id', 'md', 'latitude', and 'longitude'.\n",
    "\n",
    "        Returns:\n",
    "        pd.DataFrame\n",
    "            A DataFrame with 'chosen_id', 'Heel_Lat', 'Heel_Lon', 'Toe_Lat', 'Toe_Lon', 'Mid_Lat', 'Mid_Lon'.\n",
    "\n",
    "        Example:\n",
    "        >>> data = {\n",
    "        ...     \"chosen_id\": [1001, 1001, 1001, 1002, 1002],\n",
    "        ...     \"md\": [5000, 5100, 5200, 6000, 6100],\n",
    "        ...     \"latitude\": [31.388, 31.389, 31.387, 31.400, 31.401],\n",
    "        ...     \"longitude\": [-103.314, -103.315, -103.316, -103.318, -103.319]\n",
    "        ... }\n",
    "        >>> df = pd.DataFrame(data)\n",
    "        >>> extract_heel_toe_mid_lat_lon(df)\n",
    "        chosen_id  Heel_Lat  Heel_Lon  Toe_Lat  Toe_Lon  Mid_Lat  Mid_Lon\n",
    "        0     1001    31.388  -103.314   31.387  -103.316  31.3875 -103.315\n",
    "        1     1002    31.400  -103.318   31.401  -103.319  31.4005 -103.3185\n",
    "        \"\"\"\n",
    "        # Ensure the data is sorted by MD in ascending order\n",
    "        well_trajectory = well_trajectory.sort_values(by=[\"chosen_id\", \"md\"], ascending=True)\n",
    "\n",
    "        # Group by 'chosen_id' and extract heel/toe lat/lon\n",
    "        heel_toe_df = (\n",
    "            well_trajectory.groupby(\"chosen_id\")\n",
    "            .agg(\n",
    "                heel_lat=(\"latitude\", \"first\"),\n",
    "                heel_lon=(\"longitude\", \"first\"),\n",
    "                toe_lat=(\"latitude\", \"last\"),\n",
    "                toe_lon=(\"longitude\", \"last\"),\n",
    "            )\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "        # Calculate midpoints\n",
    "        heel_toe_df[\"mid_Lat\"] = (heel_toe_df[\"heel_lat\"] + heel_toe_df[\"toe_lat\"]) / 2\n",
    "        heel_toe_df[\"mid_Lon\"] = (heel_toe_df[\"heel_lon\"] + heel_toe_df[\"toe_lon\"]) / 2\n",
    "\n",
    "        return heel_toe_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
