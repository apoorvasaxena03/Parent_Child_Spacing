{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # Importing pandas package\n",
    "\n",
    "# Set the maximum number of columns to display to None\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import numpy as np # Importing numpy package\n",
    "\n",
    "from typing import Dict, Tuple, List, Union # Importing specific types from typing module\n",
    "\n",
    "import re # Importing regular expression package\n",
    "\n",
    "from src.database_manager import DatabricksOdbcConnector # Importing DatabricksOdbcConnector class from database_manager module\n",
    "from src.utils import reorder_columns # Importing reorder_columns function from utils module\n",
    "\n",
    "from scipy.spatial.distance import cdist # Importing cdist function from scipy package\n",
    "\n",
    "import time\n",
    "\n",
    "import pyproj # Importing pyproj package\n",
    "\n",
    "from custom_logger import CustomLogger # Importing CustomLogger class from custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpacingIKPairs:\n",
    "    \"\"\"\n",
    "    Class for identifying spacing IK pairs in a given dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, db: DatabricksOdbcConnector, header_df: pd.DataFrame , log_dir: str = \"./logs\"):\n",
    "        \"\"\"\n",
    "        Initializes the SpacingIKPairs class with a database connection and table name.\n",
    "\n",
    "        Args:\n",
    "            db (DatabricksOdbcConnector): Database connection object.\n",
    "            table_name (str): Name of the table to be processed.\n",
    "        \"\"\"\n",
    "        self.header_df = header_df # Header DataFrame\n",
    "        self.logger = CustomLogger(\"spacing_ik_pairs\", \"SpacingIKLogger\", log_dir).get_logger() # Custom logger\n",
    "        self.db = db # Database connection\n",
    "\n",
    "        self.logger.info(f\"SpacingIKPairs instance initialized.\")\n",
    "\n",
    "    def check_required_columns(self) -> bool:\n",
    "        \"\"\"\n",
    "        Checks if the required columns are present in the header DataFrame.\n",
    "\n",
    "        Returns:\n",
    "            bool: True if all required columns are present, False otherwise.\n",
    "        \"\"\"\n",
    "        required_columns = [\"chosen_id\", \"lease_name\", \"well_name\", \"rsv_cat\", \"bench\", \"first_prod_date\", \"hole_direction\"]\n",
    "        missing_columns = [col for col in required_columns if col not in self.header_df.columns]\n",
    "\n",
    "        if missing_columns:\n",
    "            self.logger.warning(f\"Missing columns: {missing_columns}\")\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def get_directional_survey_data(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Retrieves directional data from the databricks.\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: DataFrame containing the directional data from databricks.\n",
    "        \"\"\"\n",
    "        # Get the unique chosen_ids for horizontal wells only\n",
    "        chosen_ids = \", \".join(f\"'{id}'\" for id in self.header_df[self.header_df['hole_direction']=='H']['chosen_id'].unique())\n",
    "\n",
    "        try:\n",
    "            self.db.connect()\n",
    "\n",
    "            query = f\"\"\"\n",
    "            SELECT\n",
    "                LEFT(uwi, 10) AS chosen_id, \n",
    "                station_md_uscust AS md, \n",
    "                station_tvd_uscust AS tvd,\n",
    "                inclination, \n",
    "                azimuth, \n",
    "                latitude, \n",
    "                longitude, \n",
    "                x_offset_uscust AS `deviation_E/W`,\n",
    "                ew_direction,\n",
    "                y_offset_uscust AS `deviation_N/S`,\n",
    "                ns_direction,\n",
    "                point_type\n",
    "                \n",
    "            FROM ihs_sp.well.well_directional_survey_station\n",
    "            WHERE LEFT(uwi, 10) IN ({chosen_ids})\n",
    "            order by uwi, md;\n",
    "            \"\"\"\n",
    "\n",
    "            return self.db.execute_query(query)\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error retrieving directional data from databricks: {e}\")\n",
    "        finally:\n",
    "            self.db.close()\n",
    "\n",
    "    def determine_utm_zone(self, longitude: float) -> int:\n",
    "        \"\"\"\n",
    "        Determines the UTM zone based on a given longitude.\n",
    "        \"\"\"\n",
    "        return int((longitude + 180) / 6) + 1\n",
    "    \n",
    "    def batch_latlon_to_utm(self, lat: np.ndarray, lon: np.ndarray, utm_zone: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Converts arrays of latitudes and longitudes to UTM coordinates in meters for a given UTM zone.\n",
    "        \"\"\"\n",
    "        proj_utm = pyproj.Transformer.from_crs(\n",
    "            \"EPSG:4326\", f\"EPSG:326{utm_zone}\", always_xy=True\n",
    "        )\n",
    "        \n",
    "        return proj_utm.transform(lon, lat)\n",
    "    \n",
    "    def compute_mean_elevation(self,df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Computes the mean elevation (mean z value) for each ChosenID.\n",
    "\n",
    "        Parameters:\n",
    "        - df (pd.DataFrame): DataFrame containing 'ChosenID' and 'z' columns.\n",
    "\n",
    "        Returns:\n",
    "        - pd.DataFrame: DataFrame with 'ChosenID' and corresponding mean 'z' values.\n",
    "        \"\"\"\n",
    "        mean_z_df = df.groupby(\"ChosenID\", as_index=False)[\"z\"].mean()\n",
    "        mean_z_df.rename(columns={\"z\": \"elevation\"}, inplace=True)\n",
    "        return mean_z_df\n",
    "\n",
    "    def compute_utm_coordinates(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Computes UTM (x, y, z) coordinates for multiple wells, using surface location to determine UTM zones.\n",
    "        Converts UTM coordinates from meters to feet. Uses vectorized batch processing for performance.\n",
    "\n",
    "        Parameters:\n",
    "        - df (pd.DataFrame): Original directional survey DataFrame.\n",
    "\n",
    "        Returns:\n",
    "        - pd.DataFrame: DataFrame with all original columns + x, y, z (in feet), and utm_zone.\n",
    "        \"\"\"\n",
    "        start_time = time.time()  # Start timing\n",
    "\n",
    "        # Step 1: Sort dataframe by md to identify surface location\n",
    "        df = df.sort_values(by=[\"chosen_id\", \"md\"], ascending=[True, True])\n",
    "        \n",
    "        # Step 2: Determine UTM zones using the surface location (first row per well)\n",
    "        surface_locs = df.groupby(\"chosen_id\").first()[[\"latitude\", \"longitude\"]]\n",
    "        surface_locs[\"utm_zone\"] = surface_locs[\"longitude\"].apply(self.determine_utm_zone)\n",
    "\n",
    "        # Merge UTM zones back into the original dataframe\n",
    "        df = df.merge(surface_locs[[\"utm_zone\"]], on=\"chosen_id\", how=\"left\")\n",
    "\n",
    "        self.logger.info(f\"‚úÖ Determined UTM zones in {time.time() - start_time:.4f} seconds.\")\n",
    "\n",
    "        # Step 3: Batch transformation for each unique UTM zone\n",
    "        start_transform_time = time.time()\n",
    "        unique_zones = df[\"utm_zone\"].unique()\n",
    "        utm_converters: Dict[int, Tuple[np.ndarray, np.ndarray]] = {}\n",
    "\n",
    "        for zone in unique_zones:\n",
    "            subset = df[df[\"utm_zone\"] == zone]\n",
    "            easting, northing = self.batch_latlon_to_utm(subset[\"latitude\"].values, subset[\"longitude\"].values, zone)\n",
    "            utm_converters[zone] = (easting, northing)\n",
    "\n",
    "        self.logger.info(f\"‚úÖ Performed batch EPSG transformations in {time.time() - start_transform_time:.4f} seconds.\")\n",
    "\n",
    "        # Step 4: Assign the converted coordinates back to the DataFrame\n",
    "        start_assign_time = time.time()\n",
    "        df[\"x\"], df[\"y\"] = np.zeros(len(df)), np.zeros(len(df))\n",
    "\n",
    "        for zone in unique_zones:\n",
    "            mask = df[\"utm_zone\"] == zone\n",
    "            df.loc[mask, \"x\"], df.loc[mask, \"y\"] = utm_converters[zone]\n",
    "\n",
    "        self.logger.info(f\"‚úÖ Assigned transformed coordinates in {time.time() - start_assign_time:.4f} seconds.\")\n",
    "\n",
    "        # Step 5: Convert UTM coordinates from meters to feet (Conversion factor: 1 meter = 3.28084 feet)\n",
    "        df[\"x\"] *= 3.28084\n",
    "        df[\"y\"] *= 3.28084\n",
    "        \n",
    "        df[\"z\"] = -df[\"tvd\"] # Elevation is negative TVD\n",
    "\n",
    "        self.logger.info(f\"‚úÖ Total execution time: {time.time() - start_time:.4f} seconds.\")\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def filter_after_heel_point(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Filters the dataframe to include all rows for each chosen_id where the first occurrence \n",
    "        of either '80' or 'heel' appears in the point_type column and all subsequent rows.\n",
    "\n",
    "        Parameters:\n",
    "        df (pd.DataFrame): A dataframe containing directional survey data with a 'chosen_id' column and 'point_type' column.\n",
    "\n",
    "        Returns:\n",
    "        pd.DataFrame: Filtered dataframe containing rows from the first occurrence of '80' or 'heel' onward.\n",
    "        \"\"\"\n",
    "\n",
    "        # Convert 'point_type' to lowercase and check for '80' or 'heel'\n",
    "        mask = df['point_type'].str.lower().str.contains(r'80|heel', regex=True, na=False)\n",
    "\n",
    "        # Identify the first occurrence for each chosen_id\n",
    "        idx_start = df[mask].groupby('chosen_id', sort=False).head(1).index\n",
    "\n",
    "        # Create a mapping of chosen_id to the starting index\n",
    "        start_idx_map = dict(zip(df.loc[idx_start, 'chosen_id'], idx_start))\n",
    "\n",
    "        # Create a boolean mask using NumPy to filter rows\n",
    "        chosen_ids = df['chosen_id'].values\n",
    "        indices = np.arange(len(df))\n",
    "\n",
    "        # Get the minimum start index for each row's chosen_id\n",
    "        start_indices = np.vectorize(start_idx_map.get, otypes=[float])(chosen_ids)\n",
    "\n",
    "        # Mask rows where index is greater than or equal to the start index\n",
    "        valid_rows = indices >= start_indices\n",
    "\n",
    "        return df[valid_rows].reset_index(drop=True)\n",
    "    \n",
    "    def extract_heel_toe_mid_lat_lon(self, well_trajectory: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Extract the heel, toe, and mid-point latitude/longitude for each chosen_id in the well trajectory DataFrame.\n",
    "\n",
    "        Parameters:\n",
    "        well_trajectory: pd.DataFrame\n",
    "            DataFrame containing well trajectory data, including 'chosen_id', 'md', 'latitude', and 'longitude'.\n",
    "\n",
    "        Returns:\n",
    "        pd.DataFrame\n",
    "            A DataFrame with 'chosen_id', 'Heel_Lat', 'Heel_Lon', 'Toe_Lat', 'Toe_Lon', 'Mid_Lat', 'Mid_Lon'.\n",
    "\n",
    "        Example:\n",
    "        >>> data = {\n",
    "        ...     \"chosen_id\": [1001, 1001, 1001, 1002, 1002],\n",
    "        ...     \"md\": [5000, 5100, 5200, 6000, 6100],\n",
    "        ...     \"latitude\": [31.388, 31.389, 31.387, 31.400, 31.401],\n",
    "        ...     \"longitude\": [-103.314, -103.315, -103.316, -103.318, -103.319]\n",
    "        ... }\n",
    "        >>> df = pd.DataFrame(data)\n",
    "        >>> extract_heel_toe_mid_lat_lon(df)\n",
    "        chosen_id  Heel_Lat  Heel_Lon  Toe_Lat  Toe_Lon  Mid_Lat  Mid_Lon\n",
    "        0     1001    31.388  -103.314   31.387  -103.316  31.3875 -103.315\n",
    "        1     1002    31.400  -103.318   31.401  -103.319  31.4005 -103.3185\n",
    "        \"\"\"\n",
    "        # Ensure the data is sorted by MD in ascending order\n",
    "        well_trajectory = well_trajectory.sort_values(by=[\"chosen_id\", \"md\"], ascending=True)\n",
    "\n",
    "        # Group by 'chosen_id' and extract heel/toe lat/lon\n",
    "        heel_toe_df = (\n",
    "            well_trajectory.groupby(\"chosen_id\")\n",
    "            .agg(\n",
    "                heel_lat=(\"latitude\", \"first\"),\n",
    "                heel_lon=(\"longitude\", \"first\"),\n",
    "                toe_lat=(\"latitude\", \"last\"),\n",
    "                toe_lon=(\"longitude\", \"last\"),\n",
    "            )\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "        # Calculate midpoints\n",
    "        heel_toe_df[\"mid_Lat\"] = (heel_toe_df[\"heel_lat\"] + heel_toe_df[\"toe_lat\"]) / 2\n",
    "        heel_toe_df[\"mid_Lon\"] = (heel_toe_df[\"heel_lon\"] + heel_toe_df[\"toe_lon\"]) / 2\n",
    "\n",
    "        return heel_toe_df\n",
    "    \n",
    "    def get_direction(self, lat1: np.ndarray, lon1: np.ndarray, lat2: np.ndarray, lon2: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Determine the relative direction of (lat2, lon2) with respect to (lat1, lon1).\n",
    "        \n",
    "        Parameters:\n",
    "        lat1, lon1: np.ndarray\n",
    "            Latitude and longitude of the first well.\n",
    "        lat2, lon2: np.ndarray\n",
    "            Latitude and longitude of the second well.\n",
    "        \n",
    "        Returns:\n",
    "        np.ndarray\n",
    "            Array indicating the direction (e.g., North, South, East, West) of well B relative to well A.\n",
    "        \"\"\"\n",
    "        lat_diff = lat2 - lat1\n",
    "        lon_diff = lon2 - lon1\n",
    "\n",
    "        conditions = [\n",
    "            np.abs(lat_diff) > np.abs(lon_diff),\n",
    "            lat_diff > 0,\n",
    "            lon_diff > 0\n",
    "        ]\n",
    "\n",
    "        choices = [\"N\", \"S\", \"E\", \"W\"]\n",
    "        \n",
    "        return np.select(\n",
    "            [conditions[0] & conditions[1], conditions[0] & ~conditions[1], ~conditions[0] & conditions[2], ~conditions[0] & ~conditions[2]],\n",
    "            choices\n",
    "        )\n",
    "    \n",
    "    def calculate_drill_direction_vectorized(self, well_trajectories: Dict[str, pd.DataFrame], i_indices: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Vectorized function to determine the drilling direction of multiple wells using NumPy operations.\n",
    "        \n",
    "        Parameters:\n",
    "        well_trajectories: Dict[str, pd.DataFrame]\n",
    "            Dictionary containing well trajectory data indexed by ChosenID.\n",
    "        i_indices: np.ndarray\n",
    "            Array of ChosenID whose drill directions need to be calculated.\n",
    "        \n",
    "        Returns:\n",
    "        np.ndarray\n",
    "            Array containing \"EW\" (East-West) or \"NS\" (North-South) for each well.\n",
    "        \"\"\"\n",
    "        azimuth_values = np.array([well_trajectories[i][\"azimuth\"].median() if not well_trajectories[i].empty else np.nan for i in i_indices])\n",
    "        \n",
    "        conditions = (45 <= azimuth_values) & (azimuth_values < 135) | (225 <= azimuth_values) & (azimuth_values < 315)\n",
    "        drill_directions = np.where(np.isnan(azimuth_values), \"Unknown\", np.where(conditions, \"EW\", \"NS\"))\n",
    "        \n",
    "        return drill_directions\n",
    "    \n",
    "    def calculate_3D_distance_matrix(self,\n",
    "        trajectories: Dict[str, pd.DataFrame], i_indices: np.ndarray, k_indices: np.ndarray\n",
    "    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Fully vectorized 3D distance calculations for well pairs using NumPy and Pandas.\n",
    "        \n",
    "        Parameters:\n",
    "        trajectories: Dict[str, pd.DataFrame]\n",
    "            Dictionary containing well trajectory data indexed by well ID.\n",
    "        i_indices: np.ndarray\n",
    "            Array of well IDs representing the first well in each pair.\n",
    "        k_indices: np.ndarray\n",
    "            Array of well IDs representing the second well in each pair.\n",
    "        \n",
    "        Returns:\n",
    "        Tuple[np.ndarray, np.ndarray, np.ndarray]\n",
    "            - Horizontal distances between the well pairs.\n",
    "            - Vertical distances between the well pairs.\n",
    "            - 3D distances between the well pairs.\n",
    "        \"\"\"\n",
    "        # üöÄ Precompute mean (midpoint) for each well ID across all wells at once\n",
    "        all_trajectories_df = pd.concat(trajectories.values(), keys=trajectories.keys()).reset_index(drop=True)\n",
    "\n",
    "        midpoints_df = all_trajectories_df.groupby(\"chosen_id\")[[\"x\", \"y\", \"tvd\"]].mean()\n",
    "\n",
    "        # Convert to NumPy arrays for fast lookup\n",
    "        well_ids = midpoints_df.index.to_numpy()\n",
    "        midpoints = midpoints_df.to_numpy()\n",
    "\n",
    "        # Create a mapping from well ID to its index\n",
    "        well_id_to_idx = {well_id: idx for idx, well_id in enumerate(well_ids)}\n",
    "\n",
    "        # Efficiently extract midpoints using NumPy indexing\n",
    "        mid_A = midpoints[np.array([well_id_to_idx[i] for i in i_indices])]\n",
    "        mid_B = midpoints[np.array([well_id_to_idx[k] for k in k_indices])]\n",
    "\n",
    "        # Compute distances\n",
    "        vertical_distances = np.abs(mid_A[:, 2] - mid_B[:, 2])\n",
    "        mid_B[:, 2] = mid_A[:, 2]  # Align Well B to Well A‚Äôs TVD\n",
    "\n",
    "        horizontal_distances = np.linalg.norm(mid_A[:, :2] - mid_B[:, :2], axis=1)\n",
    "        total_3D_distances = np.sqrt(horizontal_distances**2 + vertical_distances**2)\n",
    "\n",
    "        return horizontal_distances, vertical_distances, total_3D_distances\n",
    "    \n",
    "    def create_i_k_pairs(self, df: pd.DataFrame, trajectories: Union[Dict[str, pd.DataFrame], pd.DataFrame]) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Generate the i_k_pairs DataFrame, computing horizontal and vertical distances, \n",
    "        3D distances, drilling directions, and relative directions between well pairs.\n",
    "        \n",
    "        Parameters:\n",
    "        df: pd.DataFrame\n",
    "            DataFrame containing well metadata with:\n",
    "            - \"chosen_id\" (str): Unique well identifier.\n",
    "\n",
    "        trajectories: Union[Dict[str, pd.DataFrame], pd.DataFrame]\n",
    "            Either:\n",
    "            - A dictionary mapping well IDs (\"chosen_id\") to trajectory DataFrames.\n",
    "            - A single DataFrame containing all trajectory data (must have \"chosen_id\" column).\n",
    "            \n",
    "        Each trajectory DataFrame should include:\n",
    "        - \"md\" (float): Measured depth.\n",
    "        - \"tvd\" (float): True vertical depth.\n",
    "        - \"inclination\" (float): Inclination angle in degrees.\n",
    "        - \"azimuth\" (float): represents the drilling direction.\n",
    "        - \"latitude\" (float): Latitude values, define the geographical position.\n",
    "        - \"longitude\" (float): Longitude values, define the geographical position.\n",
    "        - \"x\" (float): X-coordinate in a Cartesian coordinate system.\n",
    "        - \"y\" (float): Y-coordinate in a Cartesian coordinate system.\n",
    "        - \"z\" (float): Z-coordinate in a Cartesian coordinate system (elevation).\n",
    "        \n",
    "        Returns:\n",
    "        pd.DataFrame\n",
    "            DataFrame containing pairs of wells (`i_uwi`, `k_uwi`) with their computed distances \n",
    "            and directional relationships.\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Convert to dictionary if input is a DataFrame\n",
    "        step1_start = time.time()\n",
    "        if isinstance(trajectories, pd.DataFrame):\n",
    "            if \"chosen_id\" not in trajectories.columns:\n",
    "                raise ValueError(\"üö® Error: Trajectory DataFrame must contain a 'chosen_id' column.\")\n",
    "            trajectories = {cid: group for cid, group in trajectories.groupby(\"chosen_id\")}\n",
    "        step1_end = time.time()\n",
    "        self.logger.info(f\"‚úÖ Step 1: Converted trajectory DataFrame to dictionary in {step1_end - step1_start:.4f} seconds.\")\n",
    "\n",
    "        # Get unique chosen_id from df\n",
    "        step2_start = time.time()\n",
    "        chosen_ids = df[\"chosen_id\"].unique()\n",
    "        missing_ids = [cid for cid in chosen_ids if cid not in trajectories]\n",
    "\n",
    "        if missing_ids:\n",
    "            self.logger.info(f\"‚ö†Ô∏è The following chosen_id do not exist in the trajectory data and will be excluded: {missing_ids}\")\n",
    "\n",
    "        df = df[df[\"chosen_id\"].isin(trajectories)] # Filter out missing IDs in the DataFrame\n",
    "        chosen_ids = df[\"chosen_id\"].unique() # Update chosen_ids without missing IDs\n",
    "        step2_end = time.time()\n",
    "        self.logger.info(f\"‚úÖ Step 2: Extracted unique chosen_id in {step2_end - step2_start:.4f} seconds.\")\n",
    "\n",
    "        # Generate all possible pairs (excluding self-comparison)\n",
    "        step3_start = time.time()\n",
    "        i_uwi, k_uwi = np.meshgrid(chosen_ids, chosen_ids, indexing='ij')\n",
    "        i_uwi, k_uwi = i_uwi.ravel(), k_uwi.ravel()\n",
    "\n",
    "        # Remove self-comparisons\n",
    "        valid_mask = i_uwi != k_uwi\n",
    "        i_uwi, k_uwi = i_uwi[valid_mask], k_uwi[valid_mask]\n",
    "        step3_end = time.time()\n",
    "        self.logger.info(f\"‚úÖ Step 3: Generated well pairs in {step3_end - step3_start:.4f} seconds.\")\n",
    "\n",
    "        # üöÄ Optimized Heel/Toe Extraction (Vectorized)\n",
    "        step4_start = time.time()\n",
    "        heel_toe_df = pd.concat(\n",
    "            [self.extract_heel_toe_mid_lat_lon(trajectories[cid]) for cid in chosen_ids], ignore_index=True\n",
    "        )\n",
    "        heel_toe_dict = heel_toe_df.set_index(\"chosen_id\").to_dict(orient=\"index\")\n",
    "        step4_end = time.time()\n",
    "        self.logger.info(f\"‚úÖ Step 4: Heel/Toe extraction took {step4_end - step4_start:.4f} seconds.\")\n",
    "\n",
    "        # Efficiently extract values using vectorized lookups\n",
    "        step5_start = time.time()\n",
    "        mid_lat_i = np.array([heel_toe_dict[i][\"mid_Lat\"] for i in i_uwi])\n",
    "        mid_lon_i = np.array([heel_toe_dict[i][\"mid_Lon\"] for i in i_uwi])\n",
    "        mid_lat_k = np.array([heel_toe_dict[k][\"mid_Lat\"] for k in k_uwi])\n",
    "        mid_lon_k = np.array([heel_toe_dict[k][\"mid_Lon\"] for k in k_uwi])\n",
    "        step5_end = time.time()\n",
    "        self.logger.info(f\"‚úÖ Step 5: Heel/Toe dictionary lookup took {step5_end - step5_start:.4f} seconds.\")\n",
    "\n",
    "        # üöÄ Optimized Distance Calculation (Fully Vectorized)\n",
    "        step6_start = time.time()\n",
    "        horizontal_dist, vertical_dist, total_3D_dist = self.calculate_3D_distance_matrix(trajectories, i_uwi, k_uwi)\n",
    "        step6_end = time.time()\n",
    "        self.logger.info(f\"‚úÖ Step 6: Distance calculations took {step6_end - step6_start:.4f} seconds.\")\n",
    "\n",
    "        # Compute drill directions\n",
    "        step7_start = time.time()\n",
    "        drill_directions = self.calculate_drill_direction_vectorized(trajectories, i_uwi)\n",
    "        step7_end = time.time()\n",
    "        self.logger.info(f\"‚úÖ Step 7: Drill direction calculation took {step7_end - step7_start:.4f} seconds.\")\n",
    "\n",
    "        # Determine directional relationship\n",
    "        step8_start = time.time()\n",
    "        ward_of_i = self.get_direction(mid_lat_i, mid_lon_i, mid_lat_k, mid_lon_k)\n",
    "        step8_end = time.time()\n",
    "        self.logger.info(f\"‚úÖ Step 8: Directional relationship calculation took {step8_end - step8_start:.4f} seconds.\")\n",
    "\n",
    "        # Compute mean elevation\n",
    "        step9_start = time.time()\n",
    "        elevation_df = self.compute_mean_elevation(df)\n",
    "        elevation_dict = elevation_df.set_index(\"ChosenID\")[\"elevation\"].to_dict()\n",
    "\n",
    "        # Add elevation values to pairs\n",
    "        elevation_i = np.array([elevation_dict.get(i, np.nan) for i in i_uwi])\n",
    "        elevation_k = np.array([elevation_dict.get(k, np.nan) for k in k_uwi])\n",
    "        step9_end = time.time()\n",
    "        self.logger.info(f\"‚úÖ Step 9: Mean elevation calculation took {step9_end - step9_start:.4f} seconds.\")\n",
    "\n",
    "        # Create DataFrame\n",
    "        step10_start = time.time()\n",
    "        result_df = pd.DataFrame({\n",
    "            \"i_uwi\": i_uwi,\n",
    "            \"k_uwi\": k_uwi,\n",
    "            \"horizontal_dist\": horizontal_dist,\n",
    "            \"vertical_dist\": vertical_dist,\n",
    "            \"3D_ft_dist\": total_3D_dist,\n",
    "            \"drill_direction\": drill_directions,\n",
    "            \"ward_of_i\": ward_of_i,\n",
    "            \"elevation_i\": elevation_i,\n",
    "            \"elevation_k\": elevation_k\n",
    "        })\n",
    "        step10_end = time.time()\n",
    "        self.logger.info(f\"‚úÖ Step 9: Created result DataFrame in {step10_end - step10_start:.4f} seconds.\")\n",
    "\n",
    "        total_time = time.time() - start_time\n",
    "        self.logger.info(f\"üöÄ Total Execution Time: {total_time:.4f} seconds.\")\n",
    "\n",
    "        return result_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
