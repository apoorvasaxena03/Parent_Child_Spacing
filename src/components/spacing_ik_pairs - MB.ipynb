{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Well Bundles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing / Installing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # Importing pandas package\n",
    "\n",
    "# Set the maximum number of columns to display to None\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "import numpy as np # Importing numpy package\n",
    "\n",
    "from typing import Dict, Tuple, List, Union # Importing specific types from typing module\n",
    "\n",
    "import re # Importing regular expression package\n",
    "\n",
    "from src.database_manager import DatabricksOdbcConnector # Importing DatabricksOdbcConnector class from database_manager module\n",
    "from src.utils import reorder_columns # Importing reorder_columns function from utils module\n",
    "\n",
    "from scipy.spatial.distance import cdist # Importing cdist function from scipy package\n",
    "\n",
    "import time\n",
    "\n",
    "import pyproj # Importing pyproj package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading Excel/csv into Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of column names for the DataFrame\n",
    "header_colms = ['Well Name', 'Chosen ID', 'Lease Name', 'RSV_CAT', 'Bench', 'First Prod Date', 'Hole Direction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_excel('MB Header.xlsx',dtype={'Chosen ID':str},parse_dates=['First Prod Date'], usecols=header_colms) # Reading an Excel file into a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.rename(columns={\n",
    "    'Chosen ID':'ChosenID',\n",
    "    'Well Name':'WellName',\n",
    "    'RSV_CAT':'RES_CAT',\n",
    "    'Bench':'Landing_Zone',\n",
    "    'First Prod Date':'FirstProdDate',\n",
    "    'Hole Direction':'HoleDirection',\n",
    "    'Lease Name':'LeaseName'\n",
    "}, inplace=True) # Renaming columna in the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw['First Prod Date'] = pd.to_datetime(df_raw['FirstProdDate']) # Converting 'FirstProdDate' column to datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7703, 8)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Creating DSU Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating DSU columns names from Lease Name columns\n",
    "\n",
    "df_raw['DSU'] = df_raw['LeaseName'].apply(\n",
    "    lambda x: re.sub(r'[^a-zA-Z\\s]', ' ',  # Remove special characters, keep letters and spaces\n",
    "                     re.match(r'([^\\d]+)', str(x)).group(1) if pd.notna(x) and re.match(r'([^\\d]+)', str(x)) else str(x))  \n",
    "                    .strip()  # Strip leading/trailing spaces\n",
    ").replace(r'\\s+', ' ', regex=True)  # Collapse multiple spaces into a single space\n",
    "\n",
    "# Placing DSU next to LeaseName\n",
    "df_raw = reorder_columns(df=df_raw, columns_to_move=['DSU'], reference_column='LeaseName')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Defining Functions that is used in calculation for i-k pair dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_heel_toe_mid_lat_lon(well_trajectory: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extract the heel, toe, and mid-point latitude/longitude for each ChosenID in the well trajectory DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    well_trajectory: pd.DataFrame\n",
    "        DataFrame containing well trajectory data, including 'ChosenID', 'md', 'latitude', and 'longitude'.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame\n",
    "        A DataFrame with 'ChosenID', 'Heel_Lat', 'Heel_Lon', 'Toe_Lat', 'Toe_Lon', 'Mid_Lat', 'Mid_Lon'.\n",
    "\n",
    "    Example:\n",
    "    >>> data = {\n",
    "    ...     \"ChosenID\": [1001, 1001, 1001, 1002, 1002],\n",
    "    ...     \"md\": [5000, 5100, 5200, 6000, 6100],\n",
    "    ...     \"latitude\": [31.388, 31.389, 31.387, 31.400, 31.401],\n",
    "    ...     \"longitude\": [-103.314, -103.315, -103.316, -103.318, -103.319]\n",
    "    ... }\n",
    "    >>> df = pd.DataFrame(data)\n",
    "    >>> extract_heel_toe_mid_lat_lon(df)\n",
    "       ChosenID  Heel_Lat  Heel_Lon  Toe_Lat  Toe_Lon  Mid_Lat  Mid_Lon\n",
    "    0     1001    31.388  -103.314   31.387  -103.316  31.3875 -103.315\n",
    "    1     1002    31.400  -103.318   31.401  -103.319  31.4005 -103.3185\n",
    "    \"\"\"\n",
    "    # Ensure the data is sorted by MD in ascending order\n",
    "    well_trajectory = well_trajectory.sort_values(by=[\"ChosenID\", \"md\"], ascending=True)\n",
    "\n",
    "    # Group by 'ChosenID' and extract heel/toe lat/lon\n",
    "    heel_toe_df = (\n",
    "        well_trajectory.groupby(\"ChosenID\")\n",
    "        .agg(\n",
    "            heel_lat=(\"latitude\", \"first\"),\n",
    "            heel_lon=(\"longitude\", \"first\"),\n",
    "            toe_lat=(\"latitude\", \"last\"),\n",
    "            toe_lon=(\"longitude\", \"last\"),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Calculate midpoints\n",
    "    heel_toe_df[\"mid_Lat\"] = (heel_toe_df[\"heel_lat\"] + heel_toe_df[\"toe_lat\"]) / 2\n",
    "    heel_toe_df[\"mid_Lon\"] = (heel_toe_df[\"heel_lon\"] + heel_toe_df[\"toe_lon\"]) / 2\n",
    "\n",
    "    return heel_toe_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_direction(lat1: np.ndarray, lon1: np.ndarray, lat2: np.ndarray, lon2: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Determine the relative direction of (lat2, lon2) with respect to (lat1, lon1).\n",
    "    \n",
    "    Parameters:\n",
    "    lat1, lon1: np.ndarray\n",
    "        Latitude and longitude of the first well.\n",
    "    lat2, lon2: np.ndarray\n",
    "        Latitude and longitude of the second well.\n",
    "    \n",
    "    Returns:\n",
    "    np.ndarray\n",
    "        Array indicating the direction (e.g., North, South, East, West) of well B relative to well A.\n",
    "    \"\"\"\n",
    "    lat_diff = lat1 - lat2\n",
    "    lon_diff = lon1 - lon2\n",
    "\n",
    "    conditions = [\n",
    "        np.abs(lat_diff) > np.abs(lon_diff), # Determines if movement is more North/South\n",
    "        lat_diff > 0, # B is South of A\n",
    "        lon_diff > 0  # B is West of A\n",
    "    ]\n",
    "\n",
    "    choices = [\"N\", \"S\", \"E\", \"W\"]\n",
    "    \n",
    "    return np.select(\n",
    "        [conditions[0] & conditions[1], # More movement in North/South direction & B is South of A\n",
    "         conditions[0] & ~conditions[1], # More movement in North/South direction & B is North of A\n",
    "         ~conditions[0] & conditions[2], # More movement in East/West direction & B is West of A\n",
    "         ~conditions[0] & ~conditions[2]], # More movement in East/West direction & B is East of A\n",
    "        choices\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_drill_direction_vectorized(well_trajectories: Dict[str, pd.DataFrame], i_indices: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Optimized vectorized function to determine the drilling direction of multiple wells using NumPy operations.\n",
    "    \n",
    "    Parameters:\n",
    "    well_trajectories: Dict[str, pd.DataFrame]\n",
    "        Dictionary containing well trajectory data indexed by ChosenID.\n",
    "    i_indices: np.ndarray\n",
    "        Array of ChosenID whose drill directions need to be calculated.\n",
    "    \n",
    "    Returns:\n",
    "    np.ndarray\n",
    "        Array containing \"EW\" (East-West) or \"NS\" (North-South) for each well.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    # 🚀 Precompute medians for all wells at once\n",
    "    all_data = pd.concat(well_trajectories.values(), keys=well_trajectories.keys()).reset_index(level=0)\n",
    "    azimuth_medians = all_data.groupby(\"level_0\")[\"azimuth\"].median().to_dict()\n",
    "\n",
    "    step1_time = time.time()\n",
    "    print(f\"✅ Step 1: Precomputed azimuth medians in {step1_time - start_time:.4f} seconds.\")\n",
    "\n",
    "    # 🚀 Fast lookup using NumPy\n",
    "    azimuth_values = np.array([azimuth_medians.get(i, np.nan) for i in i_indices])\n",
    "\n",
    "    step2_time = time.time()\n",
    "    print(f\"✅ Step 2: Retrieved azimuth values in {step2_time - step1_time:.4f} seconds.\")\n",
    "\n",
    "    # 🚀 Apply vectorized conditions\n",
    "    conditions = (45 <= azimuth_values) & (azimuth_values < 135) | (225 <= azimuth_values) & (azimuth_values < 315)\n",
    "    drill_directions = np.where(np.isnan(azimuth_values), \"Unknown\", np.where(conditions, \"EW\", \"NS\"))\n",
    "\n",
    "    step3_time = time.time()\n",
    "    print(f\"✅ Step 3: Assigned drill directions in {step3_time - step2_time:.4f} seconds.\")\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"🚀 Total Execution Time: {total_time:.4f} seconds.\")\n",
    "\n",
    "    return drill_directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimized_calculate_3D_distance_matrix(\n",
    "    trajectories: Dict[str, pd.DataFrame], i_indices: np.ndarray, k_indices: np.ndarray\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Fully vectorized 3D distance calculations for well pairs using NumPy and Pandas.\n",
    "    \n",
    "    Parameters:\n",
    "    trajectories: Dict[str, pd.DataFrame]\n",
    "        Dictionary containing well trajectory data indexed by well ID.\n",
    "    i_indices: np.ndarray\n",
    "        Array of well IDs representing the first well in each pair.\n",
    "    k_indices: np.ndarray\n",
    "        Array of well IDs representing the second well in each pair.\n",
    "    \n",
    "    Returns:\n",
    "    Tuple[np.ndarray, np.ndarray, np.ndarray]\n",
    "        - Horizontal distances between the well pairs.\n",
    "        - Vertical distances between the well pairs.\n",
    "        - 3D distances between the well pairs.\n",
    "    \"\"\"\n",
    "    # 🚀 Precompute mean (midpoint) for each well ID across all wells at once\n",
    "    all_trajectories_df = pd.concat(trajectories.values(), keys=trajectories.keys()).reset_index(drop=True)\n",
    "\n",
    "    midpoints_df = all_trajectories_df.groupby(\"ChosenID\")[[\"x\", \"y\", \"tvd\"]].mean()\n",
    "\n",
    "    # Convert to NumPy arrays for fast lookup\n",
    "    well_ids = midpoints_df.index.to_numpy()\n",
    "    midpoints = midpoints_df.to_numpy()\n",
    "\n",
    "    # Create a mapping from well ID to its index\n",
    "    well_id_to_idx = {well_id: idx for idx, well_id in enumerate(well_ids)}\n",
    "\n",
    "    # Efficiently extract midpoints using NumPy indexing\n",
    "    mid_A = midpoints[np.array([well_id_to_idx[i] for i in i_indices])]\n",
    "    mid_B = midpoints[np.array([well_id_to_idx[k] for k in k_indices])]\n",
    "\n",
    "    # Compute distances\n",
    "    vertical_distances = np.abs(mid_A[:, 2] - mid_B[:, 2])\n",
    "    mid_B[:, 2] = mid_A[:, 2]  # Align Well B to Well A’s TVD\n",
    "\n",
    "    horizontal_distances = np.linalg.norm(mid_A[:, :2] - mid_B[:, :2], axis=1)\n",
    "    total_3D_distances = np.sqrt(horizontal_distances**2 + vertical_distances**2)\n",
    "\n",
    "    return horizontal_distances, vertical_distances, total_3D_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_i_k_pairs(df: pd.DataFrame, trajectories: Union[Dict[str, pd.DataFrame], pd.DataFrame]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate the i_k_pairs DataFrame, computing horizontal and vertical distances, \n",
    "    3D distances, drilling directions, and relative directions between well pairs.\n",
    "    \n",
    "    Parameters:\n",
    "    df: pd.DataFrame\n",
    "        DataFrame containing well metadata with:\n",
    "        - \"ChosenID\" (str): Unique well identifier.\n",
    "\n",
    "    trajectories: Union[Dict[str, pd.DataFrame], pd.DataFrame]\n",
    "        Either:\n",
    "        - A dictionary mapping well IDs (\"ChosenID\") to trajectory DataFrames.\n",
    "        - A single DataFrame containing all trajectory data (must have \"ChosenID\" column).\n",
    "        \n",
    "    Each trajectory DataFrame should include:\n",
    "    - \"md\" (float): Measured depth.\n",
    "    - \"tvd\" (float): True vertical depth.\n",
    "    - \"inclination\" (float): Inclination angle in degrees.\n",
    "    - \"azimuth\" (float): represents the drilling direction.\n",
    "    - \"latitude\" (float): Latitude values, define the geographical position.\n",
    "    - \"longitude\" (float): Longitude values, define the geographical position.\n",
    "    - \"x\" (float): X-coordinate in a Cartesian coordinate system.\n",
    "    - \"y\" (float): Y-coordinate in a Cartesian coordinate system.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame\n",
    "        DataFrame containing pairs of wells (`i_uwi`, `k_uwi`) with their computed distances \n",
    "        and directional relationships.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Convert to dictionary if input is a DataFrame\n",
    "    step1_start = time.time()\n",
    "    if isinstance(trajectories, pd.DataFrame):\n",
    "        if \"ChosenID\" not in trajectories.columns:\n",
    "            raise ValueError(\"🚨 Error: Trajectory DataFrame must contain a 'ChosenID' column.\")\n",
    "        trajectories = {cid: group for cid, group in trajectories.groupby(\"ChosenID\")}\n",
    "    step1_end = time.time()\n",
    "    print(f\"✅ Step 1: Converted trajectory DataFrame to dictionary in {step1_end - step1_start:.4f} seconds.\")\n",
    "\n",
    "    # Get unique ChosenIDs from df\n",
    "    step2_start = time.time()\n",
    "    chosen_ids = df[\"ChosenID\"].unique()\n",
    "    missing_ids = [cid for cid in chosen_ids if cid not in trajectories]\n",
    "\n",
    "    if missing_ids:\n",
    "        print(f\"⚠️ The following ChosenIDs do not exist in the trajectory data and will be excluded: {missing_ids}\")\n",
    "\n",
    "    df = df[df[\"ChosenID\"].isin(trajectories)] # Filter out missing IDs in the DataFrame\n",
    "    chosen_ids = df[\"ChosenID\"].unique() # Update chosen_ids without missing IDs\n",
    "    step2_end = time.time()\n",
    "    print(f\"✅ Step 2: Extracted unique ChosenIDs in {step2_end - step2_start:.4f} seconds.\")\n",
    "\n",
    "    # Generate all possible pairs (excluding self-comparison)\n",
    "    step3_start = time.time()\n",
    "    i_uwi, k_uwi = np.meshgrid(chosen_ids, chosen_ids, indexing='ij')\n",
    "    i_uwi, k_uwi = i_uwi.ravel(), k_uwi.ravel()\n",
    "\n",
    "    # Remove self-comparisons\n",
    "    valid_mask = i_uwi != k_uwi\n",
    "    i_uwi, k_uwi = i_uwi[valid_mask], k_uwi[valid_mask]\n",
    "    step3_end = time.time()\n",
    "    print(f\"✅ Step 3: Generated well pairs in {step3_end - step3_start:.4f} seconds.\")\n",
    "\n",
    "    # 🚀 Optimized Heel/Toe Extraction (Vectorized)\n",
    "    step4_start = time.time()\n",
    "    heel_toe_df = pd.concat(\n",
    "        [extract_heel_toe_mid_lat_lon(trajectories[cid]) for cid in chosen_ids], ignore_index=True\n",
    "    )\n",
    "    heel_toe_dict = heel_toe_df.set_index(\"ChosenID\").to_dict(orient=\"index\")\n",
    "    step4_end = time.time()\n",
    "    print(f\"✅ Step 4: Heel/Toe extraction took {step4_end - step4_start:.4f} seconds.\")\n",
    "\n",
    "    # Efficiently extract values using vectorized lookups\n",
    "    step5_start = time.time()\n",
    "    # heel_lat_i = np.array([heel_toe_dict[i][\"heel_lat\"] for i in i_uwi])\n",
    "    # heel_lon_i = np.array([heel_toe_dict[i][\"heel_lon\"] for i in i_uwi])\n",
    "    # toe_lat_k = np.array([heel_toe_dict[k][\"toe_lat\"] for k in k_uwi])\n",
    "    # toe_lon_k = np.array([heel_toe_dict[k][\"toe_lon\"] for k in k_uwi])\n",
    "    mid_lat_i = np.array([heel_toe_dict[i][\"mid_Lat\"] for i in i_uwi])\n",
    "    mid_lon_i = np.array([heel_toe_dict[i][\"mid_Lon\"] for i in i_uwi])\n",
    "    mid_lat_k = np.array([heel_toe_dict[k][\"mid_Lat\"] for k in k_uwi])\n",
    "    mid_lon_k = np.array([heel_toe_dict[k][\"mid_Lon\"] for k in k_uwi])\n",
    "    step5_end = time.time()\n",
    "    print(f\"✅ Step 5: Heel/Toe dictionary lookup took {step5_end - step5_start:.4f} seconds.\")\n",
    "\n",
    "    # 🚀 Optimized Distance Calculation (Fully Vectorized)\n",
    "    step6_start = time.time()\n",
    "    horizontal_dist, vertical_dist, total_3D_dist = optimized_calculate_3D_distance_matrix(trajectories, i_uwi, k_uwi)\n",
    "    step6_end = time.time()\n",
    "    print(f\"✅ Step 6: Distance calculations took {step6_end - step6_start:.4f} seconds.\")\n",
    "\n",
    "    # Compute drill directions\n",
    "    step7_start = time.time()\n",
    "    drill_directions = calculate_drill_direction_vectorized(trajectories, i_uwi)\n",
    "    step7_end = time.time()\n",
    "    print(f\"✅ Step 7: Drill direction calculation took {step7_end - step7_start:.4f} seconds.\")\n",
    "\n",
    "    # Determine directional relationship\n",
    "    step8_start = time.time()\n",
    "    ward_of_i = get_direction(mid_lat_i, mid_lon_i, mid_lat_k, mid_lon_k)\n",
    "    step8_end = time.time()\n",
    "    print(f\"✅ Step 8: Directional relationship calculation took {step8_end - step8_start:.4f} seconds.\")\n",
    "\n",
    "    # Create DataFrame\n",
    "    step9_start = time.time()\n",
    "    result_df = pd.DataFrame({\n",
    "        \"i_uwi\": i_uwi,\n",
    "        \"k_uwi\": k_uwi,\n",
    "        \"horizontal_dist\": horizontal_dist,\n",
    "        \"vertical_dist\": vertical_dist,\n",
    "        \"3D_ft_to_same\": total_3D_dist,\n",
    "        \"drill_direction\": drill_directions,\n",
    "        \"ward_of_i\": ward_of_i\n",
    "    })\n",
    "    step9_end = time.time()\n",
    "    print(f\"✅ Step 9: Created result DataFrame in {step9_end - step9_start:.4f} seconds.\")\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"🚀 Total Execution Time: {total_time:.4f} seconds.\")\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_overlap(well_A: pd.DataFrame, well_B: pd.DataFrame) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the percentage overlap between two horizontal wellbores.\n",
    "    \n",
    "    Parameters:\n",
    "    well_A: pd.DataFrame\n",
    "        Well trajectory data for Well A, including 'MD' (Measured Depth) and 'Inclination'.\n",
    "    well_B: pd.DataFrame\n",
    "        Well trajectory data for Well B, including 'MD' (Measured Depth) and 'Inclination'.\n",
    "    \n",
    "    Returns:\n",
    "    float:\n",
    "        Percentage of overlap relative to the shorter lateral.\n",
    "    \"\"\"\n",
    "    if well_A.empty or well_B.empty:\n",
    "        return 0.0\n",
    "\n",
    "    start_A, end_A = well_A[\"MD\"].min(), well_A[\"MD\"].max()\n",
    "    start_B, end_B = well_B[\"MD\"].min(), well_B[\"MD\"].max()\n",
    "\n",
    "    overlap_start = max(start_A, start_B)\n",
    "    overlap_end = min(end_A, end_B)\n",
    "\n",
    "    if overlap_start >= overlap_end:\n",
    "        return 0.0\n",
    "\n",
    "    overlap_length = overlap_end - overlap_start\n",
    "    shorter_length = min(end_A - start_A, end_B - start_B)\n",
    "\n",
    "    return (overlap_length / shorter_length) * 100 if shorter_length > 0 else 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Defining Functions that is used to compute Lat/Lon to UTM Co-Ordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_utm_zone(longitude: float) -> int:\n",
    "    \"\"\"\n",
    "    Determines the UTM zone based on a given longitude.\n",
    "    \"\"\"\n",
    "    return int((longitude + 180) / 6) + 1\n",
    "\n",
    "\n",
    "def batch_latlon_to_utm(lat: np.ndarray, lon: np.ndarray, utm_zone: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Converts arrays of latitudes and longitudes to UTM coordinates in meters for a given UTM zone.\n",
    "    \"\"\"\n",
    "    proj_utm = pyproj.Transformer.from_crs(\n",
    "        \"EPSG:4326\", f\"EPSG:326{utm_zone}\", always_xy=True\n",
    "    )\n",
    "    \n",
    "    return proj_utm.transform(lon, lat)\n",
    "\n",
    "\n",
    "def compute_utm_coordinates(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Computes UTM (x, y, z) coordinates for multiple wells, using surface location to determine UTM zones.\n",
    "    Converts UTM coordinates from meters to feet. Uses vectorized batch processing for performance.\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Original directional survey DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame with all original columns + x, y, z (in feet), and utm_zone.\n",
    "    \"\"\"\n",
    "    start_time = time.time()  # Start timing\n",
    "\n",
    "    # Step 1: Sort dataframe by md to identify surface location\n",
    "    df = df.sort_values(by=[\"ChosenID\", \"md\"], ascending=[True, True])\n",
    "    \n",
    "    # Step 2: Determine UTM zones using the surface location (first row per well)\n",
    "    surface_locs = df.groupby(\"ChosenID\").first()[[\"latitude\", \"longitude\"]]\n",
    "    surface_locs[\"utm_zone\"] = surface_locs[\"longitude\"].apply(determine_utm_zone)\n",
    "\n",
    "    # Merge UTM zones back into the original dataframe\n",
    "    df = df.merge(surface_locs[[\"utm_zone\"]], on=\"ChosenID\", how=\"left\")\n",
    "\n",
    "    print(f\"✅ Determined UTM zones in {time.time() - start_time:.4f} seconds.\")\n",
    "\n",
    "    # Step 3: Batch transformation for each unique UTM zone\n",
    "    start_transform_time = time.time()\n",
    "    unique_zones = df[\"utm_zone\"].unique()\n",
    "    utm_converters: Dict[int, Tuple[np.ndarray, np.ndarray]] = {}\n",
    "\n",
    "    for zone in unique_zones:\n",
    "        subset = df[df[\"utm_zone\"] == zone]\n",
    "        easting, northing = batch_latlon_to_utm(subset[\"latitude\"].values, subset[\"longitude\"].values, zone)\n",
    "        utm_converters[zone] = (easting, northing)\n",
    "\n",
    "    print(f\"✅ Performed batch EPSG transformations in {time.time() - start_transform_time:.4f} seconds.\")\n",
    "\n",
    "    # Step 4: Assign the converted coordinates back to the DataFrame\n",
    "    start_assign_time = time.time()\n",
    "    df[\"x\"], df[\"y\"] = np.zeros(len(df)), np.zeros(len(df))\n",
    "\n",
    "    for zone in unique_zones:\n",
    "        mask = df[\"utm_zone\"] == zone\n",
    "        df.loc[mask, \"x\"], df.loc[mask, \"y\"] = utm_converters[zone]\n",
    "\n",
    "    print(f\"✅ Assigned transformed coordinates in {time.time() - start_assign_time:.4f} seconds.\")\n",
    "\n",
    "    # Step 5: Convert UTM coordinates from meters to feet (Conversion factor: 1 meter = 3.28084 feet)\n",
    "    df[\"x\"] *= 3.28084\n",
    "    df[\"y\"] *= 3.28084\n",
    "    \n",
    "    df[\"z\"] = -df[\"tvd\"] # Elevation is negative TVD\n",
    "\n",
    "    print(f\"✅ Total execution time: {time.time() - start_time:.4f} seconds.\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def filter_after_heel_point(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filters the dataframe to include all rows for each ChosenID where the first occurrence \n",
    "    of either '80' or 'heel' appears in the point_type column and all subsequent rows.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): A dataframe containing directional survey data with a 'ChosenID' column and 'point_type' column.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Filtered dataframe containing rows from the first occurrence of '80' or 'heel' onward.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert 'point_type' to lowercase and check for '80' or 'heel'\n",
    "    mask = df['point_type'].str.lower().str.contains(r'80|heel', regex=True, na=False)\n",
    "\n",
    "    # Identify the first occurrence for each ChosenID\n",
    "    idx_start = df[mask].groupby('ChosenID', sort=False).head(1).index\n",
    "\n",
    "    # Create a mapping of ChosenID to the starting index\n",
    "    start_idx_map = dict(zip(df.loc[idx_start, 'ChosenID'], idx_start))\n",
    "\n",
    "    # Create a boolean mask using NumPy to filter rows\n",
    "    chosen_ids = df['ChosenID'].values\n",
    "    indices = np.arange(len(df))\n",
    "\n",
    "    # Get the minimum start index for each row's ChosenID\n",
    "    start_indices = np.vectorize(start_idx_map.get, otypes=[float])(chosen_ids)\n",
    "\n",
    "    # Mask rows where index is greater than or equal to the start index\n",
    "    valid_rows = indices >= start_indices\n",
    "\n",
    "    return df[valid_rows].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Testinig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['01PDP', '02PDNP', '02PA', 'OLD DUC', '03PUD', '03PA', '05PA'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw['RES_CAT'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering df_raw to include only certain RSV_CAT values\n",
    "df_raw = df_raw[df_raw['RES_CAT'].isin(['01PDP', '02PDNP', '03PUD'])].reset_index(drop=True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\apoorva.saxena\\onedrive - sitio royalties\\desktop\\project - apoorva\\python\\parent_child_spacing\\src\\database_manager.py:85: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  result_df = pd.read_sql(sql_query, self.connection)\n"
     ]
    }
   ],
   "source": [
    "# Importing Directional Survey data from Databricks\n",
    "\n",
    "databricks = DatabricksOdbcConnector()\n",
    "\n",
    "# Filtering only Horizontal wells and getting their apis\n",
    "chosen_ids = \", \".join(f\"'{id}'\" for id in df_raw[df_raw['HoleDirection']=='H']['ChosenID'].unique())\n",
    "\n",
    "try:\n",
    "    databricks.connect()\n",
    "\n",
    "    query = f\"\"\"\n",
    "    SELECT\n",
    "        LEFT(uwi, 10) AS ChosenID, \n",
    "        station_md_uscust AS md, \n",
    "        station_tvd_uscust AS tvd,\n",
    "        inclination, \n",
    "        azimuth, \n",
    "        latitude, \n",
    "        longitude, \n",
    "        x_offset_uscust AS `deviation_E/W`,\n",
    "        ew_direction,\n",
    "        y_offset_uscust AS `deviation_N/S`,\n",
    "        ns_direction,\n",
    "        point_type\n",
    "        \n",
    "    FROM ihs_sp.well.well_directional_survey_station\n",
    "    WHERE LEFT(uwi, 10) IN ({chosen_ids})\n",
    "    order by uwi, md;\n",
    "    \"\"\"\n",
    "\n",
    "    df_directional = databricks.execute_query(query)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "finally:\n",
    "    databricks.close_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Determined UTM zones in 1.0048 seconds.\n",
      "✅ Performed batch EPSG transformations in 0.3404 seconds.\n",
      "✅ Assigned transformed coordinates in 0.0172 seconds.\n",
      "✅ Total execution time: 1.3828 seconds.\n"
     ]
    }
   ],
   "source": [
    "df_with_utm = compute_utm_coordinates(df_directional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = filter_after_heel_point(df_with_utm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract_heel_toe_mid_lat_lon(filtered_df[['ChosenID','md','tvd','inclination','azimuth','latitude','longitude','x','y','z']]).to_csv(r\"C:\\Users\\Apoorva.Saxena\\OneDrive - Sitio Royalties\\Desktop\\Project - Apoorva\\MB Investigation\\HeelToe.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Step 1: Converted trajectory DataFrame to dictionary in 0.3125 seconds.\n",
      "⚠️ The following ChosenIDs do not exist in the trajectory data and will be excluded: ['4232944094', '4232941762', '4232941872', '4246134423', '4222740685', '4222740681', '4232943669', '4222741542', '4246142022', '4246142016', '4222741585', '4231744184', '4232945684', '4238341181', '4222741952', '4246142273', '4246142272', '4231745076', '4232946465', '4231745686', '4231745690', '4231745685', '4246142636', '4246142644', '4231745868', '4231745970', '4231745971', '4232946926', '4231746124', '4232947036', '4231746232', '4231746283', '4231746288', '4232947200', '4231746448', '4246143025']\n",
      "✅ Step 2: Extracted unique ChosenIDs in 0.0050 seconds.\n",
      "✅ Step 3: Generated well pairs in 1.1121 seconds.\n",
      "✅ Step 4: Heel/Toe extraction took 19.9128 seconds.\n",
      "✅ Step 5: Heel/Toe dictionary lookup took 19.1727 seconds.\n",
      "✅ Step 6: Distance calculations took 11.9329 seconds.\n",
      "✅ Step 1: Precomputed azimuth medians in 0.2777 seconds.\n",
      "✅ Step 2: Retrieved azimuth values in 4.9224 seconds.\n",
      "✅ Step 3: Assigned drill directions in 0.6738 seconds.\n",
      "🚀 Total Execution Time: 5.8738 seconds.\n",
      "✅ Step 7: Drill direction calculation took 5.8980 seconds.\n",
      "✅ Step 8: Directional relationship calculation took 0.9911 seconds.\n",
      "✅ Step 9: Created result DataFrame in 7.9618 seconds.\n",
      "🚀 Total Execution Time: 67.2999 seconds.\n"
     ]
    }
   ],
   "source": [
    "df_ik_pairs = create_i_k_pairs(df=df_raw, trajectories=filtered_df[['ChosenID','md','tvd','inclination','azimuth','latitude','longitude','x','y','z']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ik_pairs[df_ik_pairs['horizontal_dist']<=21120].to_csv(r\"C:\\Users\\Apoorva.Saxena\\OneDrive - Sitio Royalties\\Desktop\\Project - Apoorva\\MB Investigation\\MB_ikPairs_v4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ik_pairs.to_csv(r\"C:\\Users\\Apoorva.Saxena\\OneDrive - Sitio Royalties\\Desktop\\Project - Apoorva\\MB Investigation\\MB_ikPairs_FULL_v1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Polygon Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = df_raw.copy()\n",
    "ik_pair = df_ik_pairs.copy()\n",
    "\n",
    "# Sort header for efficient merging\n",
    "header_sorted = header.sort_values(by=\"ChosenID\")\n",
    "\n",
    "# Merge Landing_Zone information only once\n",
    "df_merge = ik_pair.merge(\n",
    "    header_sorted[[\"ChosenID\", \"Landing_Zone\"]].rename(columns={'ChosenID': 'i_uwi'}),\n",
    "    how=\"left\", on=\"i_uwi\"\n",
    ").merge(\n",
    "    header_sorted[[\"ChosenID\", \"Landing_Zone\"]].rename(columns={'ChosenID': 'k_uwi'}),\n",
    "    how=\"left\", on=\"k_uwi\", suffixes=(\"_i\", \"_k\")\n",
    ")\n",
    "\n",
    "# Keep only the smallest `horizontal_dist` per (i_uwi, k_uwi)\n",
    "df_grouped_horiz = df_merge.groupby(['i_uwi', 'k_uwi', 'Landing_Zone_i', 'Landing_Zone_k'])[['horizontal_dist']].min().reset_index()\n",
    "\n",
    "# Keep only the smallest `vertical_dist` per (i_uwi, k_uwi)\n",
    "df_grouped_vert = df_merge.groupby(['i_uwi', 'k_uwi', 'Landing_Zone_i', 'Landing_Zone_k'])[['vertical_dist']].min().reset_index()\n",
    "\n",
    "# Sort DataFrame efficiently\n",
    "df_sorted_horiz = df_grouped_horiz.sort_values(by=['i_uwi', 'horizontal_dist']).reset_index(drop=True)\n",
    "df_sorted_vert = df_grouped_vert.sort_values(by=['i_uwi', 'vertical_dist']).reset_index(drop=True)\n",
    "\n",
    "# Extract top 2 `k_uwi` values separately for same & different landing zones\n",
    "df_same = df_sorted_horiz[df_sorted_horiz[\"Landing_Zone_i\"] == df_sorted_horiz[\"Landing_Zone_k\"]].groupby(\"i_uwi\").head(2)\n",
    "\n",
    "df_diff = df_sorted_vert[df_sorted_vert[\"Landing_Zone_i\"] != df_sorted_vert[\"Landing_Zone_k\"]].groupby(\"i_uwi\").head(2)\n",
    "\n",
    "# Pivot for both same and different Landing Zones\n",
    "def pivot_top_two(df, zone_type):\n",
    "    \"\"\"Helper function to pivot grouped data into `k_uwi_*`, `horizontal_dist_*`, and `vertical_dist_*` columns.\"\"\"\n",
    "    df[\"rank\"] = df.groupby(\"i_uwi\").cumcount() + 1  # Create ranking (1 or 2) for each i_uwi\n",
    "\n",
    "    # Identify available columns for pivoting\n",
    "    available_cols = [\"k_uwi\"] + list(df.columns.intersection([\"horizontal_dist\", \"vertical_dist\"]))\n",
    "\n",
    "    # Pivot only available columns\n",
    "    df_pivot = df.pivot(index=\"i_uwi\", columns=\"rank\", values=available_cols)\n",
    "\n",
    "    # Correct column renaming based on the landing zone type\n",
    "    df_pivot.columns = [\n",
    "        f\"k_uwi_{zone_type}{col[1]}\" if col[0] == \"k_uwi\"\n",
    "        else f\"horizontal_dist_{zone_type}{col[1]}\" if col[0] == \"horizontal_dist\"\n",
    "        else f\"vertical_dist_{zone_type}{col[1]}\"\n",
    "        for col in df_pivot.columns\n",
    "    ]\n",
    "\n",
    "    return df_pivot.reset_index()\n",
    "\n",
    "\n",
    "# Pivot for both same and different Landing Zones\n",
    "df_same_pivot = pivot_top_two(df_same, \"same\")\n",
    "df_diff_pivot = pivot_top_two(df_diff, \"near\")\n",
    "\n",
    "final_df = df_same_pivot.merge(df_diff_pivot, how=\"outer\", on=\"i_uwi\")\n",
    "\n",
    "# Merging well attributes for `i_uwi`\n",
    "final_df = final_df.merge(header_sorted[['ChosenID','WellName','DSU','RES_CAT','Landing_Zone','FirstProdDate']].rename(columns={'ChosenID':'i_uwi'}), \n",
    "                          how=\"left\")\n",
    "\n",
    "# Merging well attributes for `k_uwi_same1`\n",
    "final_df = final_df.merge(header_sorted[['ChosenID','WellName','RES_CAT','Landing_Zone','FirstProdDate']].rename(columns={'ChosenID':'k_uwi_same1'}), \n",
    "                          how=\"left\", suffixes=(\"\", \"_same1\"), right_on=\"k_uwi_same1\", left_on=\"k_uwi_same1\")\n",
    "\n",
    "# Merging well attributes for , `k_uwi_same2`\n",
    "final_df = final_df.merge(header_sorted[['ChosenID','WellName','RES_CAT','Landing_Zone','FirstProdDate']].rename(columns={'ChosenID':'k_uwi_same2'}), \n",
    "                          how=\"left\", suffixes=(\"\", \"_same2\"), right_on=\"k_uwi_same2\", left_on=\"k_uwi_same2\")\n",
    "\n",
    "# Merging well attributes for `k_uwi_near1`\n",
    "final_df = final_df.merge(header_sorted[['ChosenID','WellName','RES_CAT','Landing_Zone','FirstProdDate']].rename(columns={'ChosenID':'k_uwi_near1'}), \n",
    "                          how=\"left\", suffixes=(\"\", \"_near1\"), right_on=\"k_uwi_near1\", left_on=\"k_uwi_near1\")\n",
    "\n",
    "# Merging well attributes for `k_uwi_near2`\n",
    "final_df = final_df.merge(header_sorted[['ChosenID','WellName','RES_CAT','Landing_Zone','FirstProdDate']].rename(columns={'ChosenID':'k_uwi_near2'}), \n",
    "                          how=\"left\", suffixes=(\"\", \"_near2\"), right_on=\"k_uwi_near2\", left_on=\"k_uwi_near2\")\n",
    "\n",
    "# Merging ik_pair\n",
    "final_df = final_df.merge(ik_pair[['i_uwi','k_uwi','vertical_dist','3D_ft_to_same']].rename(columns={\n",
    "    'k_uwi':'k_uwi_same1',\n",
    "    'vertical_dist':'vertical_dist_same1',\n",
    "    '3D_ft_to_same':'3D_ft_to_same1'\n",
    "}), \n",
    "               how='left', left_on=['i_uwi','k_uwi_same1'], right_on=['i_uwi','k_uwi_same1'], suffixes=(\"\", \"_same1\"))\n",
    "\n",
    "\n",
    "# Merging ik_pair\n",
    "final_df = final_df.merge(ik_pair[['i_uwi','k_uwi','vertical_dist','3D_ft_to_same']].rename(columns={\n",
    "    'k_uwi':'k_uwi_same2',\n",
    "    'vertical_dist':'vertical_dist_same2',\n",
    "    '3D_ft_to_same':'3D_ft_to_same2'\n",
    "}), \n",
    "               how='left', left_on=['i_uwi','k_uwi_same2'], right_on=['i_uwi','k_uwi_same2'], suffixes=(\"\", \"_same2\"))\n",
    "\n",
    "\n",
    "# Merging ik_pair\n",
    "final_df = final_df.merge(ik_pair[['i_uwi','k_uwi','horizontal_dist','3D_ft_to_same']].rename(columns={\n",
    "    'k_uwi':'k_uwi_near1',\n",
    "    'horizontal_dist':'horizontal_dist_near1',\n",
    "    '3D_ft_to_same':'3D_ft_to_near1'\n",
    "}), \n",
    "               how='left', left_on=['i_uwi','k_uwi_near1'], right_on=['i_uwi','k_uwi_near1'], suffixes=(\"\", \"_near1\"))\n",
    "\n",
    "\n",
    "# Merging ik_pair\n",
    "final_df = final_df.merge(ik_pair[['i_uwi','k_uwi','horizontal_dist','3D_ft_to_same']].rename(columns={\n",
    "    'k_uwi':'k_uwi_near2',\n",
    "    'horizontal_dist':'horizontal_dist_near2',\n",
    "    '3D_ft_to_same':'3D_ft_to_near2'\n",
    "}), \n",
    "               how='left', left_on=['i_uwi','k_uwi_near2'], right_on=['i_uwi','k_uwi_near2'], suffixes=(\"\", \"_near2\"))\n",
    "\n",
    "\n",
    "final_df = reorder_columns(final_df,['WellName', 'DSU', 'RES_CAT', 'Landing_Zone', 'FirstProdDate',\n",
    "                          'k_uwi_same1','WellName_same1','horizontal_dist_same1','vertical_dist_same1','3D_ft_to_same1','RES_CAT_same1', 'Landing_Zone_same1', 'FirstProdDate_same1',\n",
    "                         'k_uwi_same2','WellName_same2','horizontal_dist_same2','vertical_dist_same2','3D_ft_to_same2', 'RES_CAT_same2', 'Landing_Zone_same2', 'FirstProdDate_same2',\n",
    "                         'k_uwi_near1','WellName_near1','horizontal_dist_near1','vertical_dist_near1','3D_ft_to_near1', 'RES_CAT_near1', 'Landing_Zone_near1', 'FirstProdDate_near1',\n",
    "                         'k_uwi_near2','WellName_near2','horizontal_dist_near2','vertical_dist_near2','3D_ft_to_near2', 'RES_CAT_near2', 'Landing_Zone_near2', 'FirstProdDate_near2'],\n",
    "                         reference_column='i_uwi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i_uwi</th>\n",
       "      <th>WellName</th>\n",
       "      <th>DSU</th>\n",
       "      <th>RES_CAT</th>\n",
       "      <th>Landing_Zone</th>\n",
       "      <th>FirstProdDate</th>\n",
       "      <th>k_uwi_same1</th>\n",
       "      <th>WellName_same1</th>\n",
       "      <th>horizontal_dist_same1</th>\n",
       "      <th>vertical_dist_same1</th>\n",
       "      <th>3D_ft_to_same1</th>\n",
       "      <th>RES_CAT_same1</th>\n",
       "      <th>Landing_Zone_same1</th>\n",
       "      <th>FirstProdDate_same1</th>\n",
       "      <th>k_uwi_same2</th>\n",
       "      <th>WellName_same2</th>\n",
       "      <th>horizontal_dist_same2</th>\n",
       "      <th>vertical_dist_same2</th>\n",
       "      <th>3D_ft_to_same2</th>\n",
       "      <th>RES_CAT_same2</th>\n",
       "      <th>Landing_Zone_same2</th>\n",
       "      <th>FirstProdDate_same2</th>\n",
       "      <th>k_uwi_near1</th>\n",
       "      <th>WellName_near1</th>\n",
       "      <th>horizontal_dist_near1</th>\n",
       "      <th>vertical_dist_near1</th>\n",
       "      <th>3D_ft_to_near1</th>\n",
       "      <th>RES_CAT_near1</th>\n",
       "      <th>Landing_Zone_near1</th>\n",
       "      <th>FirstProdDate_near1</th>\n",
       "      <th>k_uwi_near2</th>\n",
       "      <th>WellName_near2</th>\n",
       "      <th>horizontal_dist_near2</th>\n",
       "      <th>vertical_dist_near2</th>\n",
       "      <th>3D_ft_to_near2</th>\n",
       "      <th>RES_CAT_near2</th>\n",
       "      <th>Landing_Zone_near2</th>\n",
       "      <th>FirstProdDate_near2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4200347476</td>\n",
       "      <td>UNDERWOOD C 1H</td>\n",
       "      <td>UNDERWOOD C</td>\n",
       "      <td>01PDP</td>\n",
       "      <td>SAN ANDRES</td>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>4200347639</td>\n",
       "      <td>UNDERWOOD -C- 3H</td>\n",
       "      <td>881.586121</td>\n",
       "      <td>16.328604</td>\n",
       "      <td>881.737326</td>\n",
       "      <td>01PDP</td>\n",
       "      <td>SAN ANDRES</td>\n",
       "      <td>2017-11-01</td>\n",
       "      <td>4200347590</td>\n",
       "      <td>UNDERWOOD C 2H</td>\n",
       "      <td>976.576922</td>\n",
       "      <td>6.264740</td>\n",
       "      <td>976.597016</td>\n",
       "      <td>01PDP</td>\n",
       "      <td>SAN ANDRES</td>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>4222740882</td>\n",
       "      <td>MITCHELL 47-31 B UNIT L 6H</td>\n",
       "      <td>1.419920e+06</td>\n",
       "      <td>1005.023612</td>\n",
       "      <td>1.419920e+06</td>\n",
       "      <td>01PDP</td>\n",
       "      <td>LSS</td>\n",
       "      <td>2021-08-01</td>\n",
       "      <td>4203332636</td>\n",
       "      <td>SHAFER 32-12 B UNIT L 5H</td>\n",
       "      <td>1.420324e+06</td>\n",
       "      <td>1053.199013</td>\n",
       "      <td>1.420325e+06</td>\n",
       "      <td>01PDP</td>\n",
       "      <td>LSS</td>\n",
       "      <td>2023-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4200347479</td>\n",
       "      <td>UNDERWOOD D 1H</td>\n",
       "      <td>UNDERWOOD D</td>\n",
       "      <td>01PDP</td>\n",
       "      <td>SAN ANDRES</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>4200347647</td>\n",
       "      <td>UNDERWOOD D 3H</td>\n",
       "      <td>807.636337</td>\n",
       "      <td>1.229364</td>\n",
       "      <td>807.637273</td>\n",
       "      <td>01PDP</td>\n",
       "      <td>SAN ANDRES</td>\n",
       "      <td>2018-07-01</td>\n",
       "      <td>4200347646</td>\n",
       "      <td>UNDERWOOD D 2H</td>\n",
       "      <td>900.630835</td>\n",
       "      <td>1.180140</td>\n",
       "      <td>900.631608</td>\n",
       "      <td>01PDP</td>\n",
       "      <td>SAN ANDRES</td>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>4222740882</td>\n",
       "      <td>MITCHELL 47-31 B UNIT L 6H</td>\n",
       "      <td>1.422578e+06</td>\n",
       "      <td>1019.467201</td>\n",
       "      <td>1.422578e+06</td>\n",
       "      <td>01PDP</td>\n",
       "      <td>LSS</td>\n",
       "      <td>2021-08-01</td>\n",
       "      <td>4203332636</td>\n",
       "      <td>SHAFER 32-12 B UNIT L 5H</td>\n",
       "      <td>1.422967e+06</td>\n",
       "      <td>1067.642601</td>\n",
       "      <td>1.422968e+06</td>\n",
       "      <td>01PDP</td>\n",
       "      <td>LSS</td>\n",
       "      <td>2023-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4200347484</td>\n",
       "      <td>UNDERWOOD -B- 1H</td>\n",
       "      <td>UNDERWOOD B</td>\n",
       "      <td>01PDP</td>\n",
       "      <td>SAN ANDRES</td>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>4200347640</td>\n",
       "      <td>UNDERWOOD -B- 3H</td>\n",
       "      <td>865.807922</td>\n",
       "      <td>0.410118</td>\n",
       "      <td>865.808019</td>\n",
       "      <td>01PDP</td>\n",
       "      <td>SAN ANDRES</td>\n",
       "      <td>2017-11-01</td>\n",
       "      <td>4200347609</td>\n",
       "      <td>UNDERWOOD -B- 2H</td>\n",
       "      <td>915.232283</td>\n",
       "      <td>7.197772</td>\n",
       "      <td>915.260586</td>\n",
       "      <td>01PDP</td>\n",
       "      <td>SAN ANDRES</td>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>4222740882</td>\n",
       "      <td>MITCHELL 47-31 B UNIT L 6H</td>\n",
       "      <td>1.417574e+06</td>\n",
       "      <td>982.083413</td>\n",
       "      <td>1.417574e+06</td>\n",
       "      <td>01PDP</td>\n",
       "      <td>LSS</td>\n",
       "      <td>2021-08-01</td>\n",
       "      <td>4203332636</td>\n",
       "      <td>SHAFER 32-12 B UNIT L 5H</td>\n",
       "      <td>1.418000e+06</td>\n",
       "      <td>1030.258814</td>\n",
       "      <td>1.418000e+06</td>\n",
       "      <td>01PDP</td>\n",
       "      <td>LSS</td>\n",
       "      <td>2023-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4200347590</td>\n",
       "      <td>UNDERWOOD C 2H</td>\n",
       "      <td>UNDERWOOD C</td>\n",
       "      <td>01PDP</td>\n",
       "      <td>SAN ANDRES</td>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>4200347646</td>\n",
       "      <td>UNDERWOOD D 2H</td>\n",
       "      <td>890.20523</td>\n",
       "      <td>6.998708</td>\n",
       "      <td>890.232741</td>\n",
       "      <td>01PDP</td>\n",
       "      <td>SAN ANDRES</td>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>4200347476</td>\n",
       "      <td>UNDERWOOD C 1H</td>\n",
       "      <td>976.576922</td>\n",
       "      <td>6.264740</td>\n",
       "      <td>976.597016</td>\n",
       "      <td>01PDP</td>\n",
       "      <td>SAN ANDRES</td>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>4222740882</td>\n",
       "      <td>MITCHELL 47-31 B UNIT L 6H</td>\n",
       "      <td>1.420882e+06</td>\n",
       "      <td>1011.288352</td>\n",
       "      <td>1.420883e+06</td>\n",
       "      <td>01PDP</td>\n",
       "      <td>LSS</td>\n",
       "      <td>2021-08-01</td>\n",
       "      <td>4203332636</td>\n",
       "      <td>SHAFER 32-12 B UNIT L 5H</td>\n",
       "      <td>1.421283e+06</td>\n",
       "      <td>1059.463753</td>\n",
       "      <td>1.421284e+06</td>\n",
       "      <td>01PDP</td>\n",
       "      <td>LSS</td>\n",
       "      <td>2023-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4200347609</td>\n",
       "      <td>UNDERWOOD -B- 2H</td>\n",
       "      <td>UNDERWOOD B</td>\n",
       "      <td>01PDP</td>\n",
       "      <td>SAN ANDRES</td>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>4200347639</td>\n",
       "      <td>UNDERWOOD -C- 3H</td>\n",
       "      <td>881.458045</td>\n",
       "      <td>0.586177</td>\n",
       "      <td>881.458240</td>\n",
       "      <td>01PDP</td>\n",
       "      <td>SAN ANDRES</td>\n",
       "      <td>2017-11-01</td>\n",
       "      <td>4200347484</td>\n",
       "      <td>UNDERWOOD -B- 1H</td>\n",
       "      <td>915.232283</td>\n",
       "      <td>7.197772</td>\n",
       "      <td>915.260586</td>\n",
       "      <td>01PDP</td>\n",
       "      <td>SAN ANDRES</td>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>4222740882</td>\n",
       "      <td>MITCHELL 47-31 B UNIT L 6H</td>\n",
       "      <td>1.418426e+06</td>\n",
       "      <td>989.281185</td>\n",
       "      <td>1.418427e+06</td>\n",
       "      <td>01PDP</td>\n",
       "      <td>LSS</td>\n",
       "      <td>2021-08-01</td>\n",
       "      <td>4203332636</td>\n",
       "      <td>SHAFER 32-12 B UNIT L 5H</td>\n",
       "      <td>1.418846e+06</td>\n",
       "      <td>1037.456586</td>\n",
       "      <td>1.418846e+06</td>\n",
       "      <td>01PDP</td>\n",
       "      <td>LSS</td>\n",
       "      <td>2023-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7629</th>\n",
       "      <td>4250137357</td>\n",
       "      <td>HOSS 605 E 2H</td>\n",
       "      <td>HOSS</td>\n",
       "      <td>01PDP</td>\n",
       "      <td>SAN ANDRES</td>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>4250137527</td>\n",
       "      <td>HOSS 605 5H</td>\n",
       "      <td>2182.768283</td>\n",
       "      <td>18.767687</td>\n",
       "      <td>2182.848965</td>\n",
       "      <td>01PDP</td>\n",
       "      <td>SAN ANDRES</td>\n",
       "      <td>2024-09-01</td>\n",
       "      <td>4250137525</td>\n",
       "      <td>HOSS 605 6H</td>\n",
       "      <td>2828.693442</td>\n",
       "      <td>19.277308</td>\n",
       "      <td>2828.759128</td>\n",
       "      <td>01PDP</td>\n",
       "      <td>SAN ANDRES</td>\n",
       "      <td>2024-08-01</td>\n",
       "      <td>4222740882</td>\n",
       "      <td>MITCHELL 47-31 B UNIT L 6H</td>\n",
       "      <td>1.361407e+06</td>\n",
       "      <td>468.859857</td>\n",
       "      <td>1.361407e+06</td>\n",
       "      <td>01PDP</td>\n",
       "      <td>LSS</td>\n",
       "      <td>2021-08-01</td>\n",
       "      <td>4203332636</td>\n",
       "      <td>SHAFER 32-12 B UNIT L 5H</td>\n",
       "      <td>1.357213e+06</td>\n",
       "      <td>517.035258</td>\n",
       "      <td>1.357213e+06</td>\n",
       "      <td>01PDP</td>\n",
       "      <td>LSS</td>\n",
       "      <td>2023-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7630</th>\n",
       "      <td>4250137525</td>\n",
       "      <td>HOSS 605 6H</td>\n",
       "      <td>HOSS</td>\n",
       "      <td>01PDP</td>\n",
       "      <td>SAN ANDRES</td>\n",
       "      <td>2024-08-01</td>\n",
       "      <td>4250137527</td>\n",
       "      <td>HOSS 605 5H</td>\n",
       "      <td>658.114031</td>\n",
       "      <td>0.509620</td>\n",
       "      <td>658.114228</td>\n",
       "      <td>01PDP</td>\n",
       "      <td>SAN ANDRES</td>\n",
       "      <td>2024-09-01</td>\n",
       "      <td>4250137526</td>\n",
       "      <td>HOSS 605 7H</td>\n",
       "      <td>658.73219</td>\n",
       "      <td>0.197377</td>\n",
       "      <td>658.732219</td>\n",
       "      <td>01PDP</td>\n",
       "      <td>SAN ANDRES</td>\n",
       "      <td>2024-09-01</td>\n",
       "      <td>4222740882</td>\n",
       "      <td>MITCHELL 47-31 B UNIT L 6H</td>\n",
       "      <td>1.358578e+06</td>\n",
       "      <td>449.582549</td>\n",
       "      <td>1.358578e+06</td>\n",
       "      <td>01PDP</td>\n",
       "      <td>LSS</td>\n",
       "      <td>2021-08-01</td>\n",
       "      <td>4203332636</td>\n",
       "      <td>SHAFER 32-12 B UNIT L 5H</td>\n",
       "      <td>1.354385e+06</td>\n",
       "      <td>497.75795</td>\n",
       "      <td>1.354385e+06</td>\n",
       "      <td>01PDP</td>\n",
       "      <td>LSS</td>\n",
       "      <td>2023-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7631</th>\n",
       "      <td>4250137526</td>\n",
       "      <td>HOSS 605 7H</td>\n",
       "      <td>HOSS</td>\n",
       "      <td>01PDP</td>\n",
       "      <td>SAN ANDRES</td>\n",
       "      <td>2024-09-01</td>\n",
       "      <td>4250137525</td>\n",
       "      <td>HOSS 605 6H</td>\n",
       "      <td>658.73219</td>\n",
       "      <td>0.197377</td>\n",
       "      <td>658.732219</td>\n",
       "      <td>01PDP</td>\n",
       "      <td>SAN ANDRES</td>\n",
       "      <td>2024-08-01</td>\n",
       "      <td>4250137198</td>\n",
       "      <td>HOSS 605 8H</td>\n",
       "      <td>669.399283</td>\n",
       "      <td>7.806956</td>\n",
       "      <td>669.444807</td>\n",
       "      <td>01PDP</td>\n",
       "      <td>SAN ANDRES</td>\n",
       "      <td>2021-05-01</td>\n",
       "      <td>4222740882</td>\n",
       "      <td>MITCHELL 47-31 B UNIT L 6H</td>\n",
       "      <td>1.357930e+06</td>\n",
       "      <td>449.385172</td>\n",
       "      <td>1.357930e+06</td>\n",
       "      <td>01PDP</td>\n",
       "      <td>LSS</td>\n",
       "      <td>2021-08-01</td>\n",
       "      <td>4203332636</td>\n",
       "      <td>SHAFER 32-12 B UNIT L 5H</td>\n",
       "      <td>1.353735e+06</td>\n",
       "      <td>497.560573</td>\n",
       "      <td>1.353735e+06</td>\n",
       "      <td>01PDP</td>\n",
       "      <td>LSS</td>\n",
       "      <td>2023-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7632</th>\n",
       "      <td>4250137527</td>\n",
       "      <td>HOSS 605 5H</td>\n",
       "      <td>HOSS</td>\n",
       "      <td>01PDP</td>\n",
       "      <td>SAN ANDRES</td>\n",
       "      <td>2024-09-01</td>\n",
       "      <td>4250137525</td>\n",
       "      <td>HOSS 605 6H</td>\n",
       "      <td>658.114031</td>\n",
       "      <td>0.509620</td>\n",
       "      <td>658.114228</td>\n",
       "      <td>01PDP</td>\n",
       "      <td>SAN ANDRES</td>\n",
       "      <td>2024-08-01</td>\n",
       "      <td>4250137526</td>\n",
       "      <td>HOSS 605 7H</td>\n",
       "      <td>1316.844343</td>\n",
       "      <td>0.706997</td>\n",
       "      <td>1316.844533</td>\n",
       "      <td>01PDP</td>\n",
       "      <td>SAN ANDRES</td>\n",
       "      <td>2024-09-01</td>\n",
       "      <td>4222740882</td>\n",
       "      <td>MITCHELL 47-31 B UNIT L 6H</td>\n",
       "      <td>1.359226e+06</td>\n",
       "      <td>450.09217</td>\n",
       "      <td>1.359226e+06</td>\n",
       "      <td>01PDP</td>\n",
       "      <td>LSS</td>\n",
       "      <td>2021-08-01</td>\n",
       "      <td>4203332636</td>\n",
       "      <td>SHAFER 32-12 B UNIT L 5H</td>\n",
       "      <td>1.355035e+06</td>\n",
       "      <td>498.26757</td>\n",
       "      <td>1.355035e+06</td>\n",
       "      <td>01PDP</td>\n",
       "      <td>LSS</td>\n",
       "      <td>2023-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7633</th>\n",
       "      <td>4250137554</td>\n",
       "      <td>BADGER 709 7XH</td>\n",
       "      <td>BADGER</td>\n",
       "      <td>01PDP</td>\n",
       "      <td>SAN ANDRES</td>\n",
       "      <td>2024-09-01</td>\n",
       "      <td>4250136993</td>\n",
       "      <td>BADGER 709 C 5XH</td>\n",
       "      <td>606.979677</td>\n",
       "      <td>22.967147</td>\n",
       "      <td>607.414042</td>\n",
       "      <td>01PDP</td>\n",
       "      <td>SAN ANDRES</td>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>4250136652</td>\n",
       "      <td>BADGER 709 1XH</td>\n",
       "      <td>793.810662</td>\n",
       "      <td>31.549999</td>\n",
       "      <td>794.437391</td>\n",
       "      <td>01PDP</td>\n",
       "      <td>SAN ANDRES</td>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>4222740882</td>\n",
       "      <td>MITCHELL 47-31 B UNIT L 6H</td>\n",
       "      <td>1.329037e+06</td>\n",
       "      <td>437.759768</td>\n",
       "      <td>1.329038e+06</td>\n",
       "      <td>01PDP</td>\n",
       "      <td>LSS</td>\n",
       "      <td>2021-08-01</td>\n",
       "      <td>4203332636</td>\n",
       "      <td>SHAFER 32-12 B UNIT L 5H</td>\n",
       "      <td>1.325104e+06</td>\n",
       "      <td>485.935169</td>\n",
       "      <td>1.325104e+06</td>\n",
       "      <td>01PDP</td>\n",
       "      <td>LSS</td>\n",
       "      <td>2023-08-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7634 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           i_uwi          WellName          DSU RES_CAT Landing_Zone  \\\n",
       "0     4200347476    UNDERWOOD C 1H  UNDERWOOD C   01PDP   SAN ANDRES   \n",
       "1     4200347479    UNDERWOOD D 1H  UNDERWOOD D   01PDP   SAN ANDRES   \n",
       "2     4200347484  UNDERWOOD -B- 1H  UNDERWOOD B   01PDP   SAN ANDRES   \n",
       "3     4200347590    UNDERWOOD C 2H  UNDERWOOD C   01PDP   SAN ANDRES   \n",
       "4     4200347609  UNDERWOOD -B- 2H  UNDERWOOD B   01PDP   SAN ANDRES   \n",
       "...          ...               ...          ...     ...          ...   \n",
       "7629  4250137357     HOSS 605 E 2H         HOSS   01PDP   SAN ANDRES   \n",
       "7630  4250137525       HOSS 605 6H         HOSS   01PDP   SAN ANDRES   \n",
       "7631  4250137526       HOSS 605 7H         HOSS   01PDP   SAN ANDRES   \n",
       "7632  4250137527       HOSS 605 5H         HOSS   01PDP   SAN ANDRES   \n",
       "7633  4250137554    BADGER 709 7XH       BADGER   01PDP   SAN ANDRES   \n",
       "\n",
       "     FirstProdDate k_uwi_same1    WellName_same1 horizontal_dist_same1  \\\n",
       "0       2017-05-01  4200347639  UNDERWOOD -C- 3H            881.586121   \n",
       "1       2018-06-01  4200347647    UNDERWOOD D 3H            807.636337   \n",
       "2       2017-09-01  4200347640  UNDERWOOD -B- 3H            865.807922   \n",
       "3       2017-09-01  4200347646    UNDERWOOD D 2H             890.20523   \n",
       "4       2017-09-01  4200347639  UNDERWOOD -C- 3H            881.458045   \n",
       "...            ...         ...               ...                   ...   \n",
       "7629    2022-04-01  4250137527       HOSS 605 5H           2182.768283   \n",
       "7630    2024-08-01  4250137527       HOSS 605 5H            658.114031   \n",
       "7631    2024-09-01  4250137525       HOSS 605 6H             658.73219   \n",
       "7632    2024-09-01  4250137525       HOSS 605 6H            658.114031   \n",
       "7633    2024-09-01  4250136993  BADGER 709 C 5XH            606.979677   \n",
       "\n",
       "      vertical_dist_same1  3D_ft_to_same1 RES_CAT_same1 Landing_Zone_same1  \\\n",
       "0               16.328604      881.737326         01PDP         SAN ANDRES   \n",
       "1                1.229364      807.637273         01PDP         SAN ANDRES   \n",
       "2                0.410118      865.808019         01PDP         SAN ANDRES   \n",
       "3                6.998708      890.232741         01PDP         SAN ANDRES   \n",
       "4                0.586177      881.458240         01PDP         SAN ANDRES   \n",
       "...                   ...             ...           ...                ...   \n",
       "7629            18.767687     2182.848965         01PDP         SAN ANDRES   \n",
       "7630             0.509620      658.114228         01PDP         SAN ANDRES   \n",
       "7631             0.197377      658.732219         01PDP         SAN ANDRES   \n",
       "7632             0.509620      658.114228         01PDP         SAN ANDRES   \n",
       "7633            22.967147      607.414042         01PDP         SAN ANDRES   \n",
       "\n",
       "     FirstProdDate_same1 k_uwi_same2    WellName_same2 horizontal_dist_same2  \\\n",
       "0             2017-11-01  4200347590    UNDERWOOD C 2H            976.576922   \n",
       "1             2018-07-01  4200347646    UNDERWOOD D 2H            900.630835   \n",
       "2             2017-11-01  4200347609  UNDERWOOD -B- 2H            915.232283   \n",
       "3             2018-09-01  4200347476    UNDERWOOD C 1H            976.576922   \n",
       "4             2017-11-01  4200347484  UNDERWOOD -B- 1H            915.232283   \n",
       "...                  ...         ...               ...                   ...   \n",
       "7629          2024-09-01  4250137525       HOSS 605 6H           2828.693442   \n",
       "7630          2024-09-01  4250137526       HOSS 605 7H             658.73219   \n",
       "7631          2024-08-01  4250137198       HOSS 605 8H            669.399283   \n",
       "7632          2024-08-01  4250137526       HOSS 605 7H           1316.844343   \n",
       "7633          2018-09-01  4250136652    BADGER 709 1XH            793.810662   \n",
       "\n",
       "      vertical_dist_same2  3D_ft_to_same2 RES_CAT_same2 Landing_Zone_same2  \\\n",
       "0                6.264740      976.597016         01PDP         SAN ANDRES   \n",
       "1                1.180140      900.631608         01PDP         SAN ANDRES   \n",
       "2                7.197772      915.260586         01PDP         SAN ANDRES   \n",
       "3                6.264740      976.597016         01PDP         SAN ANDRES   \n",
       "4                7.197772      915.260586         01PDP         SAN ANDRES   \n",
       "...                   ...             ...           ...                ...   \n",
       "7629            19.277308     2828.759128         01PDP         SAN ANDRES   \n",
       "7630             0.197377      658.732219         01PDP         SAN ANDRES   \n",
       "7631             7.806956      669.444807         01PDP         SAN ANDRES   \n",
       "7632             0.706997     1316.844533         01PDP         SAN ANDRES   \n",
       "7633            31.549999      794.437391         01PDP         SAN ANDRES   \n",
       "\n",
       "     FirstProdDate_same2 k_uwi_near1              WellName_near1  \\\n",
       "0             2017-09-01  4222740882  MITCHELL 47-31 B UNIT L 6H   \n",
       "1             2018-09-01  4222740882  MITCHELL 47-31 B UNIT L 6H   \n",
       "2             2017-09-01  4222740882  MITCHELL 47-31 B UNIT L 6H   \n",
       "3             2017-05-01  4222740882  MITCHELL 47-31 B UNIT L 6H   \n",
       "4             2017-09-01  4222740882  MITCHELL 47-31 B UNIT L 6H   \n",
       "...                  ...         ...                         ...   \n",
       "7629          2024-08-01  4222740882  MITCHELL 47-31 B UNIT L 6H   \n",
       "7630          2024-09-01  4222740882  MITCHELL 47-31 B UNIT L 6H   \n",
       "7631          2021-05-01  4222740882  MITCHELL 47-31 B UNIT L 6H   \n",
       "7632          2024-09-01  4222740882  MITCHELL 47-31 B UNIT L 6H   \n",
       "7633          2016-05-01  4222740882  MITCHELL 47-31 B UNIT L 6H   \n",
       "\n",
       "      horizontal_dist_near1 vertical_dist_near1  3D_ft_to_near1 RES_CAT_near1  \\\n",
       "0              1.419920e+06         1005.023612    1.419920e+06         01PDP   \n",
       "1              1.422578e+06         1019.467201    1.422578e+06         01PDP   \n",
       "2              1.417574e+06          982.083413    1.417574e+06         01PDP   \n",
       "3              1.420882e+06         1011.288352    1.420883e+06         01PDP   \n",
       "4              1.418426e+06          989.281185    1.418427e+06         01PDP   \n",
       "...                     ...                 ...             ...           ...   \n",
       "7629           1.361407e+06          468.859857    1.361407e+06         01PDP   \n",
       "7630           1.358578e+06          449.582549    1.358578e+06         01PDP   \n",
       "7631           1.357930e+06          449.385172    1.357930e+06         01PDP   \n",
       "7632           1.359226e+06           450.09217    1.359226e+06         01PDP   \n",
       "7633           1.329037e+06          437.759768    1.329038e+06         01PDP   \n",
       "\n",
       "     Landing_Zone_near1 FirstProdDate_near1 k_uwi_near2  \\\n",
       "0                   LSS          2021-08-01  4203332636   \n",
       "1                   LSS          2021-08-01  4203332636   \n",
       "2                   LSS          2021-08-01  4203332636   \n",
       "3                   LSS          2021-08-01  4203332636   \n",
       "4                   LSS          2021-08-01  4203332636   \n",
       "...                 ...                 ...         ...   \n",
       "7629                LSS          2021-08-01  4203332636   \n",
       "7630                LSS          2021-08-01  4203332636   \n",
       "7631                LSS          2021-08-01  4203332636   \n",
       "7632                LSS          2021-08-01  4203332636   \n",
       "7633                LSS          2021-08-01  4203332636   \n",
       "\n",
       "                WellName_near2  horizontal_dist_near2 vertical_dist_near2  \\\n",
       "0     SHAFER 32-12 B UNIT L 5H           1.420324e+06         1053.199013   \n",
       "1     SHAFER 32-12 B UNIT L 5H           1.422967e+06         1067.642601   \n",
       "2     SHAFER 32-12 B UNIT L 5H           1.418000e+06         1030.258814   \n",
       "3     SHAFER 32-12 B UNIT L 5H           1.421283e+06         1059.463753   \n",
       "4     SHAFER 32-12 B UNIT L 5H           1.418846e+06         1037.456586   \n",
       "...                        ...                    ...                 ...   \n",
       "7629  SHAFER 32-12 B UNIT L 5H           1.357213e+06          517.035258   \n",
       "7630  SHAFER 32-12 B UNIT L 5H           1.354385e+06           497.75795   \n",
       "7631  SHAFER 32-12 B UNIT L 5H           1.353735e+06          497.560573   \n",
       "7632  SHAFER 32-12 B UNIT L 5H           1.355035e+06           498.26757   \n",
       "7633  SHAFER 32-12 B UNIT L 5H           1.325104e+06          485.935169   \n",
       "\n",
       "      3D_ft_to_near2 RES_CAT_near2 Landing_Zone_near2 FirstProdDate_near2  \n",
       "0       1.420325e+06         01PDP                LSS          2023-08-01  \n",
       "1       1.422968e+06         01PDP                LSS          2023-08-01  \n",
       "2       1.418000e+06         01PDP                LSS          2023-08-01  \n",
       "3       1.421284e+06         01PDP                LSS          2023-08-01  \n",
       "4       1.418846e+06         01PDP                LSS          2023-08-01  \n",
       "...              ...           ...                ...                 ...  \n",
       "7629    1.357213e+06         01PDP                LSS          2023-08-01  \n",
       "7630    1.354385e+06         01PDP                LSS          2023-08-01  \n",
       "7631    1.353735e+06         01PDP                LSS          2023-08-01  \n",
       "7632    1.355035e+06         01PDP                LSS          2023-08-01  \n",
       "7633    1.325104e+06         01PDP                LSS          2023-08-01  \n",
       "\n",
       "[7634 rows x 38 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(r\"C:\\Users\\Apoorva.Saxena\\OneDrive - Sitio Royalties\\Desktop\\Project - Apoorva\\MB Investigation\\MB_ikPairs_v1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['horizontal_dist'] <= 20_000].to_csv(r\"C:\\Users\\Apoorva.Saxena\\OneDrive - Sitio Royalties\\Desktop\\Project - Apoorva\\MB Investigation\\MB_ikPairs_v3.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
